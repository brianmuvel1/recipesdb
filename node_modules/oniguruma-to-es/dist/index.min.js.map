{
  "version": 3,
  "sources": ["../src/index.js", "../src/utils.js", "../src/options.js", "../src/unicode.js", "../src/tokenize.js", "../src/traverse.js", "../src/parse.js", "../src/subclass-strategies.js", "../node_modules/emoji-regex-xs/index.mjs", "../src/transform.js", "../src/generate.js", "../node_modules/regex-utilities/src/index.js", "../node_modules/regex/src/subclass.js", "../node_modules/regex/src/utils.js", "../node_modules/regex/src/atomic.js", "../node_modules/regex-recursion/src/index.js"],
  "sourcesContent": ["import {transform} from './transform.js';\nimport {generate} from './generate.js';\nimport {Accuracy, getOptions, Target} from './options.js';\nimport {parse} from './parse.js';\nimport {tokenize} from './tokenize.js';\nimport {atomic, possessive, RegExpSubclass} from 'regex/internals';\nimport {recursion} from 'regex-recursion';\n\n// The transformation and error checking for Oniguruma's unique syntax and behavior differences\n// compared to native JS RegExp is layered into all steps of the compilation process:\n// 1. Tokenizer: Understands Oniguruma syntax, with many large and small differences from JS.\n// 2. Parser: Builds an Oniguruma AST from the tokens with understanding of Oniguruma differences.\n// 3. Transformer: Converts the Oniguruma AST to a Regex+ AST that preserves all Oniguruma\n//    behavior. This is true even in cases of non-native-JS features that are supported by both\n//    Regex+ and Oniguruma but with subtly different behavior in each (subroutines, flag x).\n// 4. Generator: Converts the Regex+ AST to a Regex+ pattern, flags, and options.\n// 5. Compiler: Components of the Regex+ libray are used to transpile several remaining features\n//    that aren't native to JS (atomic groups, possessive quantifiers, recursion). Regex+ uses a\n//    strict superset of JS RegExp syntax, so using it allows this library to benefit from not\n//    reinventing the wheel for complex features that Regex+ already knows how to transpile to JS.\n\n/**\n@typedef {{\n  accuracy?: keyof Accuracy;\n  avoidSubclass?: boolean;\n  flags?: import('./tokenize.js').OnigurumaFlags;\n  global?: boolean;\n  hasIndices?: boolean;\n  maxRecursionDepth?: number | null;\n  target?: keyof Target;\n  tmGrammar?: boolean;\n  verbose?: boolean;\n}} OnigurumaToEsOptions\n@typedef {{\n  useEmulationGroups?: boolean;\n  strategy?: string;\n}} EmulatedRegExpOptions\n*/\n\n/**\nAccepts an Oniguruma pattern and returns the details needed to construct an equivalent JavaScript `RegExp`.\n@param {string} pattern Oniguruma regex pattern.\n@param {OnigurumaToEsOptions} [options]\n@returns {{\n  pattern: string;\n  flags: string;\n  subclass?: EmulatedRegExpOptions;\n}}\n*/\nfunction toDetails(pattern, options) {\n  const opts = getOptions(options);\n  const tokenized = tokenize(pattern, opts.flags);\n  const onigurumaAst = parse(tokenized, {\n    skipBackrefValidation: opts.tmGrammar,\n    verbose: opts.verbose,\n  });\n  const regexAst = transform(onigurumaAst, {\n    accuracy: opts.accuracy,\n    avoidSubclass: opts.avoidSubclass,\n    bestEffortTarget: opts.target,\n  });\n  const generated = generate(regexAst, opts);\n  pattern = possessive(recursion(generated.pattern));\n  const atomized = atomic(pattern, {useEmulationGroups: !opts.avoidSubclass});\n  const useEmulationGroups = atomized !== pattern && !opts.avoidSubclass;\n  pattern = atomized;\n  const result = {\n    pattern,\n    flags: `${opts.hasIndices ? 'd' : ''}${opts.global ? 'g' : ''}${generated.flags}${generated.options.disable.v ? 'u' : 'v'}`,\n  };\n  if (useEmulationGroups || regexAst._strategy) {\n    result.subclass = {\n      useEmulationGroups,\n      strategy: regexAst._strategy ?? null,\n    };\n  }\n  return result;\n}\n\n/**\nReturns an Oniguruma AST generated from an Oniguruma pattern.\n@param {string} pattern Oniguruma regex pattern.\n@param {{\n  flags?: import('./tokenize.js').OnigurumaFlags;\n}} [options]\n@returns {import('./parse.js').OnigurumaAst}\n*/\nfunction toOnigurumaAst(pattern, options) {\n  return parse(tokenize(pattern, options?.flags));\n}\n\n/**\nAccepts an Oniguruma pattern and returns an equivalent JavaScript `RegExp`.\n@param {string} pattern Oniguruma regex pattern.\n@param {OnigurumaToEsOptions} [options]\n@returns {RegExp | EmulatedRegExp}\n*/\nfunction toRegExp(pattern, options) {\n  const result = toDetails(pattern, options);\n  if (result.subclass) {\n    return new EmulatedRegExp(result.pattern, result.flags, result.subclass);\n  }\n  return new RegExp(result.pattern, result.flags);\n}\n\n/**\nWorks the same as JavaScript's native `RegExp` constructor in all contexts, but can be given\nresults from `toDetails` to produce the same result as `toRegExp`.\n@class\n@augments RegExp\n@param {string | EmulatedRegExp} pattern\n@param {string} [flags]\n@param {EmulatedRegExpOptions} [options]\n*/\nclass EmulatedRegExp extends RegExpSubclass {\n  #strategy;\n  constructor(pattern, flags, options) {\n    const opts = {\n      useEmulationGroups: false,\n      strategy: null,\n      ...options,\n    };\n    super(pattern, flags, {useEmulationGroups: opts.useEmulationGroups});\n    if (opts.strategy) {\n      this.#strategy = opts.strategy;\n    // The third argument `options` isn't provided when regexes are copied as part of the internal\n    // handling of string methods `matchAll` and `split`\n    } else if (pattern instanceof EmulatedRegExp) {\n      // Can read private properties of the existing object since it was created by this class\n      this.#strategy = pattern.#strategy;\n    }\n  }\n  /**\n  Called internally by all String/RegExp methods that use regexes.\n  @override\n  @param {string} str\n  @returns {RegExpExecArray | null}\n  */\n  exec(str) {\n    // Special case handling that requires coupling with pattern changes for the specific strategy\n    // in the transformer. These changes add emulation support for some common patterns that are\n    // otherwise unsupportable. Only one subclass strategy is supported per pattern\n    const exec = super.exec;\n    const useLastIndex = this.global || this.sticky;\n    const pos = this.lastIndex;\n    const strategy = this.#strategy;\n\n    // ## Support leading `(^|\\G)` and similar\n    if (strategy === 'line_or_search_start' && useLastIndex && this.lastIndex) {\n      // Reset since testing on a sliced string that we want to match at the start of\n      this.lastIndex = 0;\n      const match = exec.call(this, str.slice(pos));\n      if (match) {\n        match.input = str;\n        match.index += pos;\n        this.lastIndex += pos;\n      }\n      return match;\n    }\n\n    // ## Support leading `(?!\\G)` and similar\n    if (strategy === 'not_search_start') {\n      let match = exec.call(this, str);\n      if (match?.index === pos) {\n        const globalRe = useLastIndex ? this : new RegExp(this.source, `g${this.flags}`);\n        globalRe.lastIndex = match.index + 1;\n        match = exec.call(globalRe, str);\n      }\n      return match;\n    }\n\n    return exec.call(this, str);\n  }\n}\n\nexport {\n  EmulatedRegExp,\n  toDetails,\n  toOnigurumaAst,\n  toRegExp,\n};\n", "import {EsVersion, Target} from './options.js';\n\nconst cp = String.fromCodePoint;\nconst r = String.raw;\n\nconst envSupportsDuplicateNames = (() => {\n  try {\n    new RegExp('(?<n>)|(?<n>)');\n  } catch {\n    return false;\n  }\n  return true;\n})();\n\nconst envSupportsFlagGroups = (() => {\n  try {\n    new RegExp('(?i:)');\n  } catch {\n    return false;\n  }\n  return true;\n})();\n\nconst envSupportsFlagV = (() => {\n  try {\n    new RegExp('', 'v');\n  } catch {\n    return false;\n  }\n  return true;\n})();\n\nfunction getNewCurrentFlags(current, {enable, disable}) {\n  return {\n    dotAll: !disable?.dotAll && !!(enable?.dotAll || current.dotAll),\n    ignoreCase: !disable?.ignoreCase && !!(enable?.ignoreCase || current.ignoreCase),\n  };\n}\n\nfunction getOrCreate(map, key, defaultValue) {\n  if (!map.has(key)) {\n    map.set(key, defaultValue);\n  }\n  return map.get(key);\n}\n\nfunction hasOnlyChild(node, kidFn) {\n  return node.alternatives.length === 1 &&\n    node.alternatives[0].elements.length === 1 &&\n    (!kidFn || kidFn(node.alternatives[0].elements[0]));\n}\n\n/**\n@param {keyof Target} target\n@param {keyof Target} min\n@returns {boolean}\n*/\nfunction isMinTarget(target, min) {\n  return EsVersion[target] >= EsVersion[min];\n}\n\nfunction throwIfNot(value, msg) {\n  if (!value) {\n    throw new Error(msg ?? 'Value expected');\n  }\n  return value;\n}\n\nexport {\n  cp,\n  envSupportsDuplicateNames,\n  envSupportsFlagGroups,\n  envSupportsFlagV,\n  getNewCurrentFlags,\n  getOrCreate,\n  hasOnlyChild,\n  isMinTarget,\n  r,\n  throwIfNot,\n};\n", "import {envSupportsDuplicateNames, envSupportsFlagGroups, envSupportsFlagV} from './utils.js';\n\nconst Accuracy = /** @type {const} */ ({\n  strict: 'strict',\n  default: 'default',\n  loose: 'loose',\n});\n\nconst EsVersion = {\n  ES2018: 2018,\n  ES2024: 2024,\n  ES2025: 2025,\n};\n\nconst Target = /** @type {const} */ ({\n  auto: 'auto',\n  ES2018: 'ES2018',\n  ES2024: 'ES2024',\n  ES2025: 'ES2025',\n});\n\n/**\nReturns a complete set of options, with default values set for options that weren't provided.\n@param {import('.').OnigurumaToEsOptions} [options]\n@returns {Required<import('.').OnigurumaToEsOptions>}\n*/\nfunction getOptions(options) {\n  if (options?.target !== undefined && !Target[options.target]) {\n    throw new Error(`Unexpected target \"${options.target}\"`)\n  }\n  // Set default values\n  const opts = {\n    // Sets the level of emulation rigor/strictness.\n    accuracy: 'default',\n    // Disables advanced emulation that relies on returning a `RegExp` subclass, resulting in\n    // certain patterns not being emulatable.\n    avoidSubclass: false,\n    // Oniguruma flags; a string with `i`, `m`, and `x` in any order (all optional). Oniguruma's\n    // `m` is equivalent to JavaScript's `s` (`dotAll`).\n    flags: '',\n    // Include JavaScript flag `g` (`global`) in the result.\n    global: false,\n    // Include JavaScript flag `d` (`hasIndices`) in the result.\n    hasIndices: false,\n    // Specifies the recursion depth limit. Supported values are integers `2`\u2013`100` and `null`. If\n    // `null`, any use of recursion results in an error.\n    maxRecursionDepth: 5,\n    // JavaScript version used for generated regexes. Using `auto` detects the best value based on\n    // your environment. Later targets allow faster processing, simpler generated source, and\n    // support for additional features.\n    target: 'auto',\n    // Leave disabled unless the regex will be used in a TextMate grammar processor that merges\n    // backreferences across `begin` and `end` patterns.\n    tmGrammar: false,\n    // Disables optimizations that simplify the pattern when it doesn't change the meaning.\n    verbose: false,\n    ...options,\n  };\n  if (opts.target === 'auto') {\n    opts.target = (envSupportsDuplicateNames && envSupportsFlagGroups) ?\n      'ES2025' :\n      (envSupportsFlagV ? 'ES2024' : 'ES2018');\n  }\n  return opts;\n}\n\nexport {\n  Accuracy,\n  EsVersion,\n  getOptions,\n  Target,\n};\n", "import {cp, r} from './utils.js';\n\nconst CharsWithoutIgnoreCaseExpansion = new Set([\n  cp(0x130), // \u0130\n  cp(0x131), // \u0131\n]);\n\nfunction getIgnoreCaseMatchChars(char) {\n  // Some chars should not match the chars they case swap to\n  if (CharsWithoutIgnoreCaseExpansion.has(char)) {\n    return [char];\n  }\n  const set = new Set();\n  const lower = char.toLowerCase();\n  // Everything else is based on `lower`\n  const upper = lower.toUpperCase();\n  const title = LowerToTitleCaseMap.get(lower);\n  const altLower = LowerToAlternativeLowerCaseMap.get(lower);\n  const altUpper = LowerToAlternativeUpperCaseMap.get(lower);\n  // Exclude ucase if multiple chars; count code point length. Excludes ucase versions of German\n  // es-zed '\u00DF', ligatures like '\uFB00', and chars with no precomposed ucase like '\u0149'. See\n  // <unicode.org/Public/UNIDATA/SpecialCasing.txt>\n  if ([...upper].length === 1) {\n    set.add(upper);\n  }\n  altUpper && set.add(altUpper);\n  title && set.add(title);\n  // Lcase of '\u0130' is multiple chars, but it's excluded by `CharsWithoutIgnoreCaseExpansion`\n  set.add(lower);\n  altLower && set.add(altLower);\n  return [...set];\n}\n\n// Unicode properties must be mapped to property names supported by JS, and must also apply JS's\n// stricter rules for casing, whitespace, and underscores in Unicode property names. In order to\n// remain lightweight, this library assumes properties not in this list are Unicode script names\n// (which require a `Script=` or `sc=` prefix in JS). Unlike JS, Oniguruma doesn't support script\n// extensions, and it supports some properties that aren't supported in JS (including blocks with\n// an `In_` prefix). See also:\n// - Properties supported in Oniguruma: <github.com/kkos/oniguruma/blob/master/doc/UNICODE_PROPERTIES>\n// - Properties supported in JS by spec version: <github.com/eslint-community/regexpp/blob/main/src/unicode/properties.ts>\nconst JsUnicodeProperties = new Set([\n  // ES2024 general categories and their aliases; all are supported by Oniguruma\n  // See <github.com/mathiasbynens/unicode-match-property-value-ecmascript/blob/main/data/mappings.js>\n  'C', 'Other',\n  'Cc', 'Control', 'cntrl',\n  'Cf', 'Format',\n  'Cn', 'Unassigned',\n  'Co', 'Private_Use',\n  'Cs', 'Surrogate',\n  'L', 'Letter',\n  'LC', 'Cased_Letter',\n  'Ll', 'Lowercase_Letter',\n  'Lm', 'Modifier_Letter',\n  'Lo', 'Other_Letter',\n  'Lt', 'Titlecase_Letter',\n  'Lu', 'Uppercase_Letter',\n  'M', 'Mark', 'Combining_Mark',\n  'Mc', 'Spacing_Mark',\n  'Me', 'Enclosing_Mark',\n  'Mn', 'Nonspacing_Mark',\n  'N', 'Number',\n  'Nd', 'Decimal_Number', 'digit',\n  'Nl', 'Letter_Number',\n  'No', 'Other_Number',\n  'P', 'Punctuation', 'punct',\n  'Pc', 'Connector_Punctuation',\n  'Pd', 'Dash_Punctuation',\n  'Pe', 'Close_Punctuation',\n  'Pf', 'Final_Punctuation',\n  'Pi', 'Initial_Punctuation',\n  'Po', 'Other_Punctuation',\n  'Ps', 'Open_Punctuation',\n  'S', 'Symbol',\n  'Sc', 'Currency_Symbol',\n  'Sk', 'Modifier_Symbol',\n  'Sm', 'Math_Symbol',\n  'So', 'Other_Symbol',\n  'Z', 'Separator',\n  'Zl', 'Line_Separator',\n  'Zp', 'Paragraph_Separator',\n  'Zs', 'Space_Separator',\n\n  // ES2024 binary properties and their aliases; all are supported by Oniguruma\n  // See <tc39.es/ecma262/multipage/text-processing.html#table-binary-unicode-properties>\n  'ASCII',\n  'ASCII_Hex_Digit', 'AHex',\n  'Alphabetic', 'Alpha',\n  'Any',\n  'Assigned',\n  'Bidi_Control', 'Bidi_C',\n  'Bidi_Mirrored', 'Bidi_M',\n  'Case_Ignorable', 'CI',\n  'Cased',\n  'Changes_When_Casefolded', 'CWCF',\n  'Changes_When_Casemapped', 'CWCM',\n  'Changes_When_Lowercased', 'CWL',\n  'Changes_When_NFKC_Casefolded', 'CWKCF',\n  'Changes_When_Titlecased', 'CWT',\n  'Changes_When_Uppercased', 'CWU',\n  'Dash',\n  'Default_Ignorable_Code_Point', 'DI',\n  'Deprecated', 'Dep',\n  'Diacritic', 'Dia',\n  'Emoji',\n  'Emoji_Component', 'EComp',\n  'Emoji_Modifier', 'EMod',\n  'Emoji_Modifier_Base', 'EBase',\n  'Emoji_Presentation', 'EPres',\n  'Extended_Pictographic', 'ExtPict',\n  'Extender', 'Ext',\n  'Grapheme_Base', 'Gr_Base',\n  'Grapheme_Extend', 'Gr_Ext',\n  'Hex_Digit', 'Hex',\n  'IDS_Binary_Operator', 'IDSB',\n  'IDS_Trinary_Operator', 'IDST',\n  'ID_Continue', 'IDC',\n  'ID_Start', 'IDS',\n  'Ideographic', 'Ideo',\n  'Join_Control', 'Join_C',\n  'Logical_Order_Exception', 'LOE',\n  'Lowercase', 'Lower',\n  'Math',\n  'Noncharacter_Code_Point', 'NChar',\n  'Pattern_Syntax', 'Pat_Syn',\n  'Pattern_White_Space', 'Pat_WS',\n  'Quotation_Mark', 'QMark',\n  'Radical',\n  'Regional_Indicator', 'RI',\n  'Sentence_Terminal', 'STerm',\n  'Soft_Dotted', 'SD',\n  'Terminal_Punctuation', 'Term',\n  'Unified_Ideograph', 'UIdeo',\n  'Uppercase', 'Upper',\n  'Variation_Selector', 'VS',\n  'White_Space', 'space',\n  'XID_Continue', 'XIDC',\n  'XID_Start', 'XIDS',\n]);\n\nconst JsUnicodePropertiesMap = new Map();\nfor (const p of JsUnicodeProperties) {\n  JsUnicodePropertiesMap.set(slug(p), p);\n}\n\nconst JsUnicodePropertiesOfStrings = new Set([\n  // ES2024 properties of strings; none are supported by Oniguruma\n  'Basic_Emoji',\n  'Emoji_Keycap_Sequence',\n  'RGI_Emoji',\n  'RGI_Emoji_Flag_Sequence',\n  'RGI_Emoji_Modifier_Sequence',\n  'RGI_Emoji_Tag_Sequence',\n  'RGI_Emoji_ZWJ_Sequence',\n]);\n\nconst JsUnicodePropertiesOfStringsMap = new Map();\nfor (const p of JsUnicodePropertiesOfStrings) {\n  JsUnicodePropertiesOfStringsMap.set(slug(p), p);\n}\n\n// Unicode scripts and binary properties (and their aliases) added after ES2018\n// See <github.com/eslint-community/regexpp/blob/main/src/unicode/properties.ts>\nconst JsUnicodePropertiesPostEs2018 = new Set((\n  // ES2019 scripts\n  'Dogr Dogra Gong Gunjala_Gondi Hanifi_Rohingya Maka Makasar Medefaidrin Medf Old_Sogdian Rohg Sogd Sogdian Sogo' +\n  // ES2019 binary properties\n  ' Extended_Pictographic' +\n  // ES2020 scripts\n  ' Elym Elymaic Hmnp Nand Nandinagari Nyiakeng_Puachue_Hmong Wancho Wcho' +\n  // ES2021 scripts\n  ' Chorasmian Chrs Diak Dives_Akuru Khitan_Small_Script Kits Yezi Yezidi' +\n  // ES2021 binary properties\n  ' EBase EComp EMod EPres ExtPict' +\n  // ES2022 scripts\n  ' Cpmn Cypro_Minoan Old_Uyghur Ougr Tangsa Tnsa Toto Vith Vithkuqi' +\n  // ES2023 scripts\n  ' Gara Garay Gukh Gurung_Khema Hrkt Katakana_Or_Hiragana Kawi Kirat_Rai Krai Nag_Mundari Nagm Ol_Onal Onao Sunu Sunuwar Todhri Todr Tulu_Tigalari Tutg Unknown Zzzz'\n  // ES2024: None, but added `JsUnicodePropertiesOfStrings`\n).split(' '));\n\nconst LowerToAlternativeLowerCaseMap = new Map([\n  ['s', cp(0x17F)], // s, \u017F\n  [cp(0x17F), 's'], // \u017F, s\n]);\n\nconst LowerToAlternativeUpperCaseMap = new Map([\n  [cp(0xDF), cp(0x1E9E)], // \u00DF, \u1E9E\n  [cp(0x6B), cp(0x212A)], // k, \u212A (Kelvin)\n  [cp(0xE5), cp(0x212B)], // \u00E5, \u212B (Angstrom)\n  [cp(0x3C9), cp(0x2126)], // \u03C9, \u2126 (Ohm)\n]);\n\n// See <github.com/node-unicode/unicode-16.0.0/tree/main/General_Category/Titlecase_Letter>\nconst LowerToTitleCaseMap = new Map([\n  titleEntry(0x1C5),\n  titleEntry(0x1C8),\n  titleEntry(0x1CB),\n  titleEntry(0x1F2),\n  ...titleRange(0x1F88, 0x1F8F),\n  ...titleRange(0x1F98, 0x1F9F),\n  ...titleRange(0x1FA8, 0x1FAF),\n  titleEntry(0x1FBC),\n  titleEntry(0x1FCC),\n  titleEntry(0x1FFC),\n]);\n\n// Unlike Oniguruma's Unicode properties via `\\p` and `\\P`, these names are case sensitive and\n// don't allow inserting whitespace and underscores. Definitions at\n// <github.com/kkos/oniguruma/blob/master/doc/RE> (see: POSIX bracket: Unicode Case)\n// Note: Handling in the transformer assumes all values here are a single, negateable node that's\n// not pre-negated at the top level. It also uses ASCII versions of `graph` and `print` for target\n// `ES2018` (which doesn't allow intersection) if `accuracy` isn't `strict`\nconst PosixClassesMap = new Map([\n  ['alnum', r`[\\p{Alpha}\\p{Nd}]`],\n  ['alpha', r`\\p{Alpha}`],\n  ['ascii', r`\\p{ASCII}`],\n  ['blank', r`[\\p{Zs}\\t]`],\n  ['cntrl', r`\\p{cntrl}`],\n  ['digit', r`\\p{Nd}`],\n  ['graph', r`[\\P{space}&&\\P{cntrl}&&\\P{Cn}&&\\P{Cs}]`],\n  ['lower', r`\\p{Lower}`],\n  ['print', r`[[\\P{space}&&\\P{cntrl}&&\\P{Cn}&&\\P{Cs}]\\p{Zs}]`],\n  ['punct', r`[\\p{P}\\p{S}]`], // New value from Oniguruma 6.9.9\n  ['space', r`\\p{space}`],\n  ['upper', r`\\p{Upper}`],\n  ['word', r`[\\p{Alpha}\\p{M}\\p{Nd}\\p{Pc}]`],\n  ['xdigit', r`\\p{AHex}`],\n]);\n\n// Apart from the property names provided by Unicode, Oniguruma explicitly adds several names (see\n// <github.com/kkos/oniguruma/blob/master/doc/RE>) that can be used within `\\p{}` and `\\P{}` (those\n// below). These should be listed here in lowercase, though they aren't case sensitive when used\nconst PosixProperties = new Set([\n  'alnum',\n  'blank',\n  'graph',\n  'print',\n  'word',\n  'xdigit',\n  // The following are available with the same name in JS (see `JsUnicodeProperties`)\n  // - alpha (JS: Alpha)\n  // - ascii (JS: ASCII)\n  // - cntrl (JS: cntrl)\n  // - digit (JS: digit)\n  // - lower (JS: Lower)\n  // - punct (JS: punct)\n  // - space (JS: space)\n  // - upper (JS: Upper)\n]);\n\nfunction range(start, end) {\n  // const range = Array.from(Array(end + 1 - start), (_, i) => i + start);\n  // const range = Array(end + 1 - start).fill(start).map((x, i) => x + i);\n  const range = [];\n  for (let i = start; i <= end; i++) {\n    range.push(i);\n  }\n  return range;\n}\n\n// Generates a Unicode property lookup name: lowercase, with hyphens, spaces, and underscores removed\nfunction slug(name) {\n  return name.replace(/[- _]+/g, '').toLowerCase();\n}\n\nfunction titleEntry(codePoint) {\n  const char = cp(codePoint);\n  return [char.toLowerCase(), char];\n}\n\nfunction titleRange(start, end) {\n  return range(start, end).map(codePoint => titleEntry(codePoint));\n}\n\nconst UnicodePropertiesWithSpecificCase = new Set([\n  'Lower', 'Lowercase',\n  'Upper', 'Uppercase',\n  'Ll', 'Lowercase_Letter',\n  'Lt', 'Titlecase_Letter',\n  'Lu', 'Uppercase_Letter',\n  // The `Changes_When_*` properties (and their aliases) could be included, but they're very rare.\n  // Some other properties include a handful of chars with specific cases only, but these chars are\n  // generally extreme edge cases and using such properties case insensitively generally produces\n  // undesired behavior anyway\n]);\n\nexport {\n  getIgnoreCaseMatchChars,\n  JsUnicodeProperties,\n  JsUnicodePropertiesMap,\n  JsUnicodePropertiesOfStringsMap,\n  JsUnicodePropertiesPostEs2018,\n  PosixClassesMap,\n  PosixProperties,\n  slug,\n  UnicodePropertiesWithSpecificCase,\n};\n", "import {PosixClassesMap} from './unicode.js';\nimport {r} from './utils.js';\n\nconst TokenTypes = /** @type {const} */ ({\n  Alternator: 'Alternator',\n  Assertion: 'Assertion',\n  Backreference: 'Backreference',\n  Character: 'Character',\n  CharacterClassClose: 'CharacterClassClose',\n  CharacterClassHyphen: 'CharacterClassHyphen',\n  CharacterClassIntersector: 'CharacterClassIntersector',\n  CharacterClassOpen: 'CharacterClassOpen',\n  CharacterSet: 'CharacterSet',\n  Directive: 'Directive',\n  GroupClose: 'GroupClose',\n  GroupOpen: 'GroupOpen',\n  Subroutine: 'Subroutine',\n  Quantifier: 'Quantifier',\n  // These aren't allowed in char classes, so they aren't equivalent to JS `[\\q{}]`\n  VariableLengthCharacterSet: 'VariableLengthCharacterSet',\n  // Intermediate representation not included in results\n  EscapedNumber: 'EscapedNumber',\n});\n\nconst TokenCharacterSetKinds = {\n  any: 'any',\n  digit: 'digit',\n  dot: 'dot',\n  hex: 'hex',\n  non_newline: 'non_newline',\n  posix: 'posix',\n  property: 'property',\n  space: 'space',\n  word: 'word',\n};\n\nconst TokenDirectiveKinds = {\n  flags: 'flags',\n  keep: 'keep',\n};\n\nconst TokenGroupKinds = {\n  atomic: 'atomic',\n  capturing: 'capturing',\n  group: 'group',\n  lookahead: 'lookahead',\n  lookbehind: 'lookbehind',\n};\n\nconst EscapeCharCodes = new Map([\n  ['a',  7], // alert/bell (Not available in JS)\n  ['b',  8], // backspace (only in char classes)\n  ['e', 27], // escape (Not available in JS)\n  ['f', 12], // form feed\n  ['n', 10], // line feed\n  ['r', 13], // carriage return\n  ['t',  9], // horizontal tab\n  ['v', 11], // vertical tab\n]);\n\nconst charClassOpenPattern = r`\\[\\^?\\]?`;\nconst sharedEscapesPattern = `${\n  // Control char\n  'c.? | C(?:-.?)?'\n}|${\n  // Unicode property; Onig considers `\\p` an identity escape, but e.g. `\\p{`, `\\p{ ^L}`, and\n  // `\\p{gc=L}` are invalid\n  r`[pP]\\{(?:\\^?[\\x20\\w]+\\})?`\n}|${\n  // Hex encoded byte sequence; attempt match before other `\\xNN` hex char\n  r`x[89A-Fa-f]\\p{AHex}(?:\\\\x[89A-Fa-f]\\p{AHex})*`\n}|${\n  // Hex char\n  r`u(?:\\p{AHex}{4})? | x\\{[^\\}]*\\}? | x\\p{AHex}{0,2}`\n}|${\n  // Enclosed octal code point\n  r`o\\{[^\\}]*\\}?`\n}|${\n  // Escaped number\n  r`\\d{1,3}`\n}`;\n// Even with flag x, Onig doesn't allow whitespace to separate a quantifier from the `?` or `+`\n// that makes it lazy or possessive. Possessive suffixes don't apply to interval quantifiers\nconst quantifierRe = /[?*+][?+]?|\\{(?:\\d+(?:,\\d*)?|,\\d+)\\}\\??/;\nconst tokenRe = new RegExp(r`\n  \\\\ (?:\n    ${sharedEscapesPattern}\n    | [gk]<[^>]*>?\n    | [gk]'[^']*'?\n    | .\n  )\n  | \\( (?: \\? (?:\n    [:=!>(~]\n    | <[=!]\n    | <[^>]*>\n    | '[^']*'\n    | # (?:[^)\\\\] | \\\\.?)*\n    | [imx\\-]+[:)]\n  )?)?\n  | ${quantifierRe.source}\n  | ${charClassOpenPattern}\n  | .\n`.replace(/\\s+/g, ''), 'gsu');\nconst charClassTokenRe = new RegExp(r`\n  \\\\ (?:\n    ${sharedEscapesPattern}\n    | .\n  )\n  | \\[:[^:]*:\\]\n  | ${charClassOpenPattern}\n  | &&\n  | .\n`.replace(/\\s+/g, ''), 'gsu');\n\n/**\n@typedef {'i' | ''} FlagI\n@typedef {'m' | ''} FlagM\n@typedef {'x' | ''} FlagX\n@typedef {`${FlagI}${FlagM}${FlagX}` | `${FlagI}${FlagX}${FlagM}` | `${FlagM}${FlagI}${FlagX}` | `${FlagM}${FlagX}${FlagI}` | `${FlagX}${FlagI}${FlagM}` | `${FlagX}${FlagM}${FlagI}`} OnigurumaFlags\n@typedef {{\n  type: keyof TokenTypes;\n  raw: string;\n  [key: string]: string | number | boolean;\n}} Token\n@typedef {{\n  tokens: Array<Token>;\n  flags: {\n    dotAll: boolean;\n    extended: boolean;\n    ignoreCase: boolean;\n  };\n}} TokenizerResult\n*/\n/**\n@param {string} pattern\n@param {OnigurumaFlags} [flags] Oniguruma flags. Flag `m` is equivalent to JS flag `s`.\n@returns {TokenizerResult}\n*/\nfunction tokenize(pattern, flags = '') {\n  if (typeof pattern !== 'string') {\n    throw new Error('String expected as pattern');\n  }\n  if (!/^[imx]*$/.test(flags)) {\n    throw new Error(`Flags \"${flags}\" unsupported in Oniguruma`);\n  }\n  const xStack = [flags.includes('x')];\n  const context = {\n    getCurrentModX: () => xStack.at(-1),\n    numOpenGroups: 0,\n    popModX() {xStack.pop()},\n    pushModX(isXOn) {xStack.push(isXOn)},\n    replaceCurrentModX(isXOn) {xStack[xStack.length - 1] = isXOn},\n  };\n  let tokens = [];\n  let match;\n  tokenRe.lastIndex = 0;\n  while ((match = tokenRe.exec(pattern))) {\n    const result = getTokenWithDetails(context, pattern, match[0], tokenRe.lastIndex);\n    if (result.tokens) {\n      tokens.push(...result.tokens);\n    } else if (result.token) {\n      tokens.push(result.token);\n    }\n    if (result.lastIndex !== undefined) {\n      tokenRe.lastIndex = result.lastIndex;\n    }\n  }\n\n  const potentialUnnamedCaptureTokens = [];\n  let numNamedCaptures = 0;\n  tokens.forEach(t => {\n    if (t.type === TokenTypes.GroupOpen) {\n      if (t.kind === TokenGroupKinds.capturing) {\n        numNamedCaptures++;\n        t.number = numNamedCaptures;\n      } else if (t.raw === '(') {\n        potentialUnnamedCaptureTokens.push(t);\n      }\n    }\n  });\n  // Enable unnamed capturing groups if no named captures\n  if (!numNamedCaptures) {\n    potentialUnnamedCaptureTokens.forEach((t, i) => {\n      t.kind = TokenGroupKinds.capturing;\n      t.number = i + 1;\n    });\n  }\n  const numCaptures = numNamedCaptures || potentialUnnamedCaptureTokens.length;\n  // Can now split escaped nums accurately, accounting for number of captures\n  tokens = tokens.map(\n    t => t.type === TokenTypes.EscapedNumber ? splitEscapedNumToken(t, numCaptures) : t\n  ).flat();\n\n  return {\n    tokens,\n    flags: {\n      ignoreCase: flags.includes('i'),\n      // Onig flag m is equivalent to JS flag s\n      dotAll: flags.includes('m'),\n      // Flag x is fully handled during tokenization\n      extended: flags.includes('x'),\n    },\n  };\n}\n\nfunction getTokenWithDetails(context, pattern, m, lastIndex) {\n  const [m0, m1, m2] = m;\n  if (m0 === '[') {\n    const result = getAllTokensForCharClass(pattern, m, lastIndex);\n    return {\n      // Array of all of the char class's tokens\n      tokens: result.tokens,\n      // Jump forward to the end of the char class\n      lastIndex: result.lastIndex,\n    };\n  }\n  if (m0 === '\\\\') {\n    if ('AbBGzZ'.includes(m1)) {\n      return {\n        token: createToken(TokenTypes.Assertion, m, {\n          kind: m,\n        }),\n      };\n    }\n    if (/^\\\\g[<']/.test(m)) {\n      if (!/^\\\\g(?:<[^>]+>|'[^']+')$/.test(m)) {\n        throw new Error(`Invalid group name \"${m}\"`);\n      }\n      return {\n        token: createToken(TokenTypes.Subroutine, m),\n      };\n    }\n    if (/^\\\\k[<']/.test(m)) {\n      if (!/^\\\\k(?:<[^>]+>|'[^']+')$/.test(m)) {\n        throw new Error(`Invalid group name \"${m}\"`);\n      }\n      return {\n        token: createToken(TokenTypes.Backreference, m),\n      };\n    }\n    if (m1 === 'K') {\n      return {\n        token: createToken(TokenTypes.Directive, m, {\n          kind: TokenDirectiveKinds.keep,\n        }),\n      };\n    }\n    if (m1 === 'N') {\n      return {\n        token: createToken(TokenTypes.CharacterSet, m, {\n          kind: TokenCharacterSetKinds.non_newline,\n        }),\n      };\n    }\n    if (m1 === 'O') {\n      return {\n        token: createToken(TokenTypes.CharacterSet, m, {\n          kind: TokenCharacterSetKinds.any,\n        }),\n      };\n    }\n    if ('RX'.includes(m1)) {\n      return {\n        token: createToken(TokenTypes.VariableLengthCharacterSet, m, {\n          kind: m,\n        }),\n      };\n    }\n    // Grapheme boundaries not yet unsupported; avoid treating as an identity escape\n    if ('yY'.includes(m1)) {\n      throw new Error(`Unsupported grapheme boundary \"${m}\"`);\n    }\n    // Run last since it assumes an identity escape as final condition\n    const result = createTokenForSharedEscape(m, {inCharClass: false});\n    return Array.isArray(result) ? {tokens: result} : {token: result};\n  }\n  if (m0 === '(') {\n    // Comment group\n    if (m2 === '#') {\n      // The closing unescaped `)` isn't included in the match\n      if (pattern[lastIndex] !== ')') {\n        throw new Error('Unclosed comment group \"(?#\"');\n      }\n      return {\n        lastIndex: lastIndex + 1,\n      };\n    }\n    // Flag modifier (directive or group opener); allows solo `-`\n    if ('-imx'.includes(m2)) {\n      return {\n        token: createTokenForFlagMod(m, context),\n      };\n    }\n    // Remaining group types all reuse current flag x status\n    context.pushModX(context.getCurrentModX());\n    context.numOpenGroups++;\n    if (\n      // Unnamed capture if no named captures, else noncapturing group\n      m === '(' ||\n      // Noncapturing group\n      m === '(?:'\n    ) {\n      return {\n        token: createToken(TokenTypes.GroupOpen, m, {\n          // For `(`, will later change to `capturing` and add `number` prop if no named captures\n          kind: TokenGroupKinds.group,\n        }),\n      };\n    }\n    // Atomic group\n    if (m === '(?>') {\n      return {\n        token: createToken(TokenTypes.GroupOpen, m, {\n          kind: TokenGroupKinds.atomic,\n        }),\n      };\n    }\n    // Lookaround\n    if (m === '(?=' || m === '(?!' || m === '(?<=' || m === '(?<!') {\n      return {\n        token: createToken(TokenTypes.GroupOpen, m, {\n          kind: m2 === '<' ? TokenGroupKinds.lookbehind : TokenGroupKinds.lookahead,\n          negate: m.endsWith('!'),\n        }),\n      };\n    }\n    // Named capture (checked after lookbehind due to similar syntax)\n    if (m2 === '<' || m2 === \"'\") {\n      return {\n        token: createToken(TokenTypes.GroupOpen, m, {\n          kind: TokenGroupKinds.capturing,\n          name: m.slice(3, -1),\n          // Will add `number` in a second pass\n        }),\n      }\n    }\n    if (m2 === '(') {\n      // [TODO] Some forms are supportable\n      throw new Error(`Unsupported conditional \"${m}\"`);\n    }\n    if (m2 === '~') {\n      // [TODO] Some forms are supportable\n      throw new Error(`Unsupported absence operator \"${m}\"`);\n    }\n    if (m === '(?') {\n      throw new Error('Invalid group');\n    }\n    throw new Error(`Unexpected group \"${m}\"`);\n  }\n  if (m === ')') {\n    context.popModX();\n    context.numOpenGroups--;\n    if (context.numOpenGroups < 0) {\n      throw new Error('Unmatched \")\"');\n    }\n    return {\n      token: createToken(TokenTypes.GroupClose, m),\n    };\n  }\n  if (m === '#' && context.getCurrentModX()) {\n    // Onig's only line break char is line feed\n    const end = pattern.indexOf('\\n', lastIndex);\n    return {\n      // Jump forward to the end of the comment\n      lastIndex: end === -1 ? pattern.length : end,\n    };\n  }\n  if (/^\\s$/.test(m) && context.getCurrentModX()) {\n    const re = /\\s+/y;\n    re.lastIndex = lastIndex;\n    const rest = re.exec(pattern);\n    return {\n      // Jump forward to the end of the whitespace\n      lastIndex: rest ? re.lastIndex : lastIndex,\n    };\n  }\n  if (m === '.') {\n    return {\n      token: createToken(TokenTypes.CharacterSet, m, {\n        kind: TokenCharacterSetKinds.dot,\n      }),\n    };\n  }\n  if (m === '^' || m === '$') {\n    return {\n      token: createToken(TokenTypes.Assertion, m, {\n        kind: m,\n      }),\n    };\n  }\n  if (m === '|') {\n    return {\n      token: createToken(TokenTypes.Alternator, m),\n    };\n  }\n  if (quantifierRe.test(m)) {\n    return {\n      token: createTokenForQuantifier(m),\n    };\n  }\n  assertSingleCodePoint(m);\n  return {\n    token: createToken(TokenTypes.Character, m, {\n      value: m.codePointAt(0),\n    }),\n  };\n}\n\nfunction getAllTokensForCharClass(pattern, opener, lastIndex) {\n  assertNonEmptyCharClass(opener);\n  const tokens = [createToken(TokenTypes.CharacterClassOpen, opener, {\n    negate: opener[1] === '^',\n  })];\n  let numCharClassesOpen = 1;\n  let match;\n  charClassTokenRe.lastIndex = lastIndex;\n  while ((match = charClassTokenRe.exec(pattern))) {\n    const m = match[0];\n    // Start of nested char class\n    // POSIX classes are handled as a single token; not as a nested char class\n    if (m[0] === '[' && m[1] !== ':') {\n      assertNonEmptyCharClass(m);\n      numCharClassesOpen++;\n      tokens.push(createToken(TokenTypes.CharacterClassOpen, m, {\n        negate: m[1] === '^',\n      }));\n    } else if (m === ']') {\n      numCharClassesOpen--;\n      tokens.push(createToken(TokenTypes.CharacterClassClose, m));\n      if (!numCharClassesOpen) {\n        break;\n      }\n    } else {\n      const result = createTokenForAnyTokenWithinCharClass(m);\n      if (Array.isArray(result)) {\n        tokens.push(...result);\n      } else {\n        tokens.push(result);\n      }\n    }\n  }\n  return {\n    tokens,\n    lastIndex: charClassTokenRe.lastIndex || pattern.length,\n  }\n}\n\nfunction createTokenForAnyTokenWithinCharClass(raw) {\n  if (raw[0] === '\\\\') {\n    // Assumes an identity escape as final condition\n    return createTokenForSharedEscape(raw, {inCharClass: true});\n  }\n  // POSIX class: `[:name:]` or `[:^name:]`\n  if (raw[0] === '[') {\n    const posix = /\\[:(?<negate>\\^?)(?<name>[a-z]+):\\]/.exec(raw);\n    if (!posix || !PosixClassesMap.get(posix.groups.name)) {\n      throw new Error(`Invalid POSIX class \"${raw}\"`);\n    }\n    return createToken(TokenTypes.CharacterSet, raw, {\n      kind: TokenCharacterSetKinds.posix,\n      negate: !!posix.groups.negate,\n      value: posix.groups.name,\n    });\n  }\n  // Range (possibly invalid) or literal hyphen\n  if (raw === '-') {\n    return createToken(TokenTypes.CharacterClassHyphen, raw);\n  }\n  if (raw === '&&') {\n    return createToken(TokenTypes.CharacterClassIntersector, raw);\n  }\n  assertSingleCodePoint(raw);\n  return createToken(TokenTypes.Character, raw, {\n    value: raw.codePointAt(0),\n  });\n}\n\n// Tokens shared by base syntax and char class syntax that start with `\\`\nfunction createTokenForSharedEscape(raw, {inCharClass}) {\n  const char1 = raw[1];\n  if (char1 === 'c' || char1 === 'C') {\n    return createTokenForControlChar(raw);\n  }\n  if ('dDhHsSwW'.includes(char1)) {\n    return createTokenForShorthandCharClass(raw);\n  }\n  if (raw.startsWith(r`\\o{`)) {\n    throw new Error(`Incomplete, invalid, or unsupported octal code point \"${raw}\"`);\n  }\n  if (/^\\\\[pP]\\{/.test(raw)) {\n    if (raw.length === 3) {\n      throw new Error('Incomplete or invalid Unicode property');\n    }\n    return createTokenForUnicodeProperty(raw);\n  }\n  // Hex UTF-8 encoded byte sequence\n  if (/^\\\\x[89A-Fa-f]\\p{AHex}/u.test(raw)) {\n    try {\n      const bytes = raw.split(/\\\\x/).slice(1).map(hex => parseInt(hex, 16));\n      const decoded = new TextDecoder('utf-8', {\n        ignoreBOM: true,\n        fatal: true,\n      }).decode(new Uint8Array(bytes));\n      const encoder = new TextEncoder();\n      const tokens = [...decoded].map(char => {\n        // Since this regenerates `raw`, it might have different casing for hex A-F than the input\n        const raw = [...encoder.encode(char)].map(byte => `\\\\x${byte.toString(16)}`).join('');\n        return createToken(TokenTypes.Character, raw, {\n          value: char.codePointAt(0),\n        });\n      });\n      return tokens;\n    } catch {\n      throw new Error(`Too short or invalid multibyte code \"${raw}\"`);\n    }\n  }\n  if (char1 === 'u' || char1 === 'x') {\n    return createToken(TokenTypes.Character, raw, {\n      value: getValidatedHexCharCode(raw),\n    });\n  }\n  if (EscapeCharCodes.has(char1)) {\n    return createToken(TokenTypes.Character, raw, {\n      value: EscapeCharCodes.get(char1),\n    });\n  }\n  // Escaped number: backref (possibly invalid), null, octal, or identity escape, possibly followed\n  // by 1-2 literal digits\n  if (/\\d/.test(char1)) {\n    return createToken(TokenTypes.EscapedNumber, raw, {\n      inCharClass,\n    });\n  }\n  if (raw === '\\\\') {\n    throw new Error(r`Incomplete escape \"\\\"`);\n  }\n  // Meta `\\M-x` and `\\M-\\C-x` are unsupported; avoid treating as an identity escape\n  if (char1 === 'M') {\n    // [TODO] Supportable; see <github.com/kkos/oniguruma/blob/master/doc/SYNTAX.md#12-onig_syn_op2_esc_capital_m_bar_meta-enable-m-x>, <github.com/kkos/oniguruma/blob/43a8c3f3daf263091f3a74019d4b32ebb6417093/src/regparse.c#L4695>, <https://github.com/ammar/regexp_parser/blob/8851030feda68223d74f502335fb254a20d77016/lib/regexp_parser/expression/classes/escape_sequence.rb#L75>\n    throw new Error(`Unsupported meta \"${raw}\"`);\n  }\n  // Identity escape; count code point length\n  if ([...raw].length === 2) {\n    return createToken(TokenTypes.Character, raw, {\n      value: raw.codePointAt(1),\n    });\n  }\n  throw new Error(`Unexpected escape \"${raw}\"`);\n}\n\n/**\n@param {keyof TokenTypes} type\n@param {string} raw\n@param {{[key: string]: string | number | boolean;}} [data]\n@returns {Token}\n*/\nfunction createToken(type, raw, data) {\n  return {\n    type,\n    raw,\n    ...data,\n  };\n}\n\n// Expects `\\cx` or `\\C-x`\nfunction createTokenForControlChar(raw) {\n  const char = raw[1] === 'c' ? raw[2] : raw[3];\n  if (!char || !/[A-Za-z]/.test(char)) {\n    // Unlike JS, Onig allows any char to follow `\\c` or `\\C-`, but this is an extreme edge case\n    // [TODO] Supportable; see <github.com/kkos/oniguruma/blob/master/doc/SYNTAX.md#11-onig_syn_op2_esc_capital_c_bar_control-enable-c-x>, <github.com/kkos/oniguruma/blob/43a8c3f3daf263091f3a74019d4b32ebb6417093/src/regparse.c#L4695>\n    throw new Error(`Unsupported control character \"${raw}\"`);\n  }\n  return createToken(TokenTypes.Character, raw, {\n    value: char.toUpperCase().codePointAt(0) - 64,\n  });\n}\n\nfunction createTokenForFlagMod(raw, context) {\n  // Allows multiple `-` and solo `-` without `on` or `off` flags\n  let {on, off} = /^\\(\\?(?<on>[imx]*)(?:-(?<off>[imx\\-]*))?/.exec(raw).groups;\n  // If the capturing group didn't participate\n  off ??= '';\n  // Flag x is used directly by the tokenizer since it changes how to interpret the pattern\n  const isXOn = (context.getCurrentModX() || on.includes('x')) && !off.includes('x');\n  const enabledFlags = getFlagPropsForToken(on);\n  const disabledFlags = getFlagPropsForToken(off);\n  const flagChanges = {};\n  enabledFlags && (flagChanges.enable = enabledFlags);\n  disabledFlags && (flagChanges.disable = disabledFlags);\n  // Flag directive; ex: `(?im-x)`\n  if (raw.endsWith(')')) {\n    // Replace flag x value until the end of the current group\n    context.replaceCurrentModX(isXOn);\n    // Can't remove flag directives without flags like `(?-)`; they affect following quantifiers\n    return createToken(TokenTypes.Directive, raw, {\n      kind: TokenDirectiveKinds.flags,\n      flags: flagChanges,\n    });\n  }\n  // Flag group opener; ex: `(?im-x:`\n  if (raw.endsWith(':')) {\n    context.pushModX(isXOn);\n    context.numOpenGroups++;\n    const token = createToken(TokenTypes.GroupOpen, raw, {\n      kind: TokenGroupKinds.group,\n    });\n    if (enabledFlags || disabledFlags) {\n      token.flags = flagChanges;\n    }\n    return token;\n  }\n  throw new Error(`Unexpected flag modifier \"${raw}\"`);\n}\n\nfunction createTokenForQuantifier(raw) {\n  const data = {};\n  if (raw[0] === '{') {\n    const {min, max} = /^\\{(?<min>\\d*)(?:,(?<max>\\d*))?/.exec(raw).groups;\n    const limit = 100_000;\n    if (+min > limit || +max > limit) {\n      throw new Error('Quantifier value unsupported in Oniguruma');\n    }\n    data.min = +min;\n    data.max = max === undefined ? +min : (max === '' ? Infinity : +max);\n    data.greedy = !raw.endsWith('?');\n    // By default, Onig doesn't support making interval quantifiers possessive\n    data.possessive = false;\n  } else {\n    data.min = raw[0] === '+' ? 1 : 0;\n    data.max = raw[0] === '?' ? 1 : Infinity;\n    data.greedy = raw[1] !== '?';\n    data.possessive = raw[1] === '+';\n  }\n  return createToken(TokenTypes.Quantifier, raw, data);\n}\n\nfunction createTokenForShorthandCharClass(raw) {\n  const lower = raw[1].toLowerCase();\n  return createToken(TokenTypes.CharacterSet, raw, {\n    kind: {\n      'd': TokenCharacterSetKinds.digit,\n      'h': TokenCharacterSetKinds.hex, // Not available in JS\n      's': TokenCharacterSetKinds.space, // Different than JS\n      'w': TokenCharacterSetKinds.word,\n    }[lower],\n    negate: raw[1] !== lower,\n  });\n}\n\nfunction createTokenForUnicodeProperty(raw) {\n  const {p, neg, value} = /^\\\\(?<p>[pP])\\{(?<neg>\\^?)(?<value>[ \\w]+)/.exec(raw).groups;\n  const negate = (p === 'P' && !neg) || (p === 'p' && !!neg);\n  return createToken(TokenTypes.CharacterSet, raw, {\n    kind: TokenCharacterSetKinds.property,\n    negate,\n    value,\n  });\n}\n\nfunction getFlagPropsForToken(flags) {\n  // Don't include `false` for flags that aren't included\n  const obj = {};\n  if (flags.includes('i')) {\n    obj.ignoreCase = true;\n  }\n  if (flags.includes('m')) {\n    // Onig flag m is equivalent to JS flag s\n    obj.dotAll = true;\n  }\n  if (flags.includes('x')) {\n    obj.extended = true;\n  }\n  return Object.keys(obj).length ? obj : null;\n}\n\nfunction getValidatedHexCharCode(raw) {\n  // Note: Onig (tested 6.9.8) has a bug where bare `\\u` and `\\x` are identity escapes if they\n  // appear at the very end of the pattern, so e.g. `\\u` matches `u`, but `\\u0`, `\\u.`, and `[\\u]`\n  // are all errors, and `\\x.` and `[\\x]` are not errors but seemingly fail to match anything.\n  // Don't emulate these bugs, and just treat these cases as errors. Also, Onig treats incomplete\n  // `\\x{` (with the brace and not immediately followed by a hex digit) as an identity escape, so\n  // e.g. `\\x{` matches `x{` and `^\\x{,2}$` matches `xx`, but `\\x{2,}` and `\\x{0,2}` are errors.\n  // Don't emulate this nasty/pointless ambiguity; just treat incomplete `\\x{` as an error\n  if (/^(?:\\\\u(?!\\p{AHex}{4})|\\\\x(?!\\p{AHex}{1,2}|\\{\\p{AHex}{1,8}\\}))/u.test(raw)) {\n    throw new Error(`Incomplete or invalid escape \"${raw}\"`);\n  }\n  // Might include leading 0s\n  const hex = raw[2] === '{' ?\n    /^\\\\x\\{\\s*(?<hex>\\p{AHex}+)/u.exec(raw).groups.hex :\n    raw.slice(2);\n  const dec = parseInt(hex, 16);\n  // `\\xNN` above 0x7F is handled elsewhere as a UTF-8 encoded byte sequence\n  if (dec > 0x13FFFF) {\n    throw new Error(`Invalid out of range \"${raw}\"`);\n  } else if (dec > 0x10FFFF) {\n    throw new Error(`Invalid out of range in JS \"${raw}\"`);\n  }\n  return dec;\n}\n\n// Value is 1-3 digits, which can be a backref (possibly invalid), null, octal, or identity escape,\n// possibly followed by 1-2 literal digits\nfunction splitEscapedNumToken(token, numCaptures) {\n  const {raw, inCharClass} = token;\n  // Keep any leading 0s since they indicate octal\n  const value = raw.slice(1);\n  // Backref (possibly invalid)\n  if (\n    !inCharClass &&\n    ( // Single digit 1-9 outside a char class is always treated as a backref\n      (value !== '0' && value.length === 1) ||\n      // Leading 0 makes it octal; backrefs can't include following literal digits\n      (value[0] !== '0' && +value <= numCaptures)\n    )\n  ) {\n    return [createToken(TokenTypes.Backreference, raw)];\n  }\n  const tokens = [];\n  // Returns 1-3 matches; the first (only) might be octal\n  const matches = value.match(/^[0-7]+|\\d/g);\n  for (let i = 0; i < matches.length; i++) {\n    const m = matches[i];\n    let value;\n    // Octal digits are 0-7\n    if (i === 0 && m !== '8' && m !== '9') {\n      value = parseInt(m, 8);\n      if (value > 0o177) {\n        // Octal UTF-8 encoded byte sequence; not yet supported\n        throw new Error(r`Octal encoded byte above 177 unsupported \"${raw}\"`);\n      }\n    } else {\n      value = m.codePointAt(0);\n    }\n    tokens.push(createToken(TokenTypes.Character, (i === 0 ? '\\\\' : '') + m, {\n      value,\n    }));\n  }\n  return tokens;\n}\n\nfunction assertNonEmptyCharClass(raw) {\n  if (raw.endsWith(']')) {\n    throw new Error(`Empty character class \"${raw}\" unsupported in Oniguruma`);\n  }\n}\n\nfunction assertSingleCodePoint(raw) {\n  if ([...raw].length !== 1) {\n    throw new Error(`Expected \"${raw}\" to be a single code point`);\n  }\n}\n\nexport {\n  tokenize,\n  TokenCharacterSetKinds,\n  TokenDirectiveKinds,\n  TokenGroupKinds,\n  TokenTypes,\n};\n", "import {AstTypes, getAstTypeAliases, isLookaround} from './parse.js';\nimport {throwIfNot} from './utils.js';\n\nfunction traverse(path, state, visitor) {\n  let ast = path.node;\n  while (ast.parent) {\n    ast = ast.parent;\n  }\n  function traverseArray(array, parent) {\n    for (let i = 0; i < array.length; i++) {\n      const keyShift = traverseNode(array[i], parent, i, array);\n      i = Math.max(-1, i + keyShift);\n    }\n  }\n  function traverseNode(node, parent = null, key = null, container = null) {\n    let keyShift = 0;\n    let skipTraversingKidsOfPath = false;\n    const path = {\n      node,\n      parent,\n      key,\n      container,\n      ast,\n      remove() {\n        throwIfNot(container, 'Container expected').splice(Math.max(0, key + keyShift), 1);\n        keyShift -= 1;\n      },\n      removeAllNextSiblings() {\n        return throwIfNot(container, 'Container expected').splice(key + 1);\n      },\n      removeAllPrevSiblings() {\n        const shifted = key + keyShift;\n        keyShift -= shifted;\n        return throwIfNot(container, 'Container expected').splice(0, Math.max(0, shifted));\n      },\n      replaceWith(newNode) {\n        setParent(newNode, parent);\n        if (container) {\n          container[Math.max(0, key + keyShift)] = newNode;\n        } else {\n          parent[key] = newNode;\n        }\n      },\n      skip() {\n        skipTraversingKidsOfPath = true;\n      },\n    };\n    const visitorKey = getAstTypeAliases(node).find(key => !!visitor[key]);\n    const methods = visitorKey && visitor[visitorKey];\n    const enterFn = typeof methods === 'function' ? methods : methods?.enter;\n    const exitFn = methods?.exit;\n    enterFn?.(path, state);\n    if (!skipTraversingKidsOfPath) {\n      switch (node.type) {\n        case AstTypes.Regex:\n          traverseNode(node.pattern, node, 'pattern');\n          traverseNode(node.flags, node, 'flags');\n          break;\n        case AstTypes.Alternative:\n        case AstTypes.CharacterClass:\n          traverseArray(node.elements, node);\n          break;\n        case AstTypes.Assertion:\n          if (isLookaround(node)) {\n            traverseArray(node.alternatives, node);\n          }\n          break;\n        case AstTypes.Backreference:\n        case AstTypes.Character:\n        case AstTypes.CharacterSet:\n        case AstTypes.Directive:\n        case AstTypes.Flags:\n        case AstTypes.Recursion:\n        case AstTypes.Subroutine:\n        case AstTypes.VariableLengthCharacterSet:\n          break;\n        case AstTypes.CapturingGroup:\n        case AstTypes.Group:\n        case AstTypes.Pattern:\n          traverseArray(node.alternatives, node);\n          break;\n        case AstTypes.CharacterClassIntersection:\n          traverseArray(node.classes, node);\n          break;\n        case AstTypes.CharacterClassRange:\n          traverseNode(node.min, node, 'min');\n          traverseNode(node.max, node, 'max');\n          break;\n        case AstTypes.Quantifier:\n          traverseNode(node.element, node, 'element');\n          break;\n        default:\n          throw new Error(`Unexpected node type \"${node.type}\"`);\n      }\n    }\n    exitFn?.(path, state);\n    return keyShift;\n  }\n  traverseNode(path.node, path.parent, path.key, path.container);\n}\n\nfunction setParent(node, parent) {\n  // The traverser can work with ASTs whose nodes include or don't include `parent` props, so only\n  // update the parent if a prop for it exists\n  if ('parent' in parent) {\n    node.parent = parent;\n  }\n}\n\nexport {\n  traverse,\n};\n", "import {TokenCharacterSetKinds, TokenDirectiveKinds, TokenGroupKinds, TokenTypes} from './tokenize.js';\nimport {traverse} from './traverse.js';\nimport {JsUnicodePropertiesMap, JsUnicodePropertiesOfStringsMap, PosixProperties, slug} from './unicode.js';\nimport {getOrCreate, hasOnlyChild, r, throwIfNot} from './utils.js';\n\nconst AstTypes = {\n  Alternative: 'Alternative',\n  Assertion: 'Assertion',\n  Backreference: 'Backreference',\n  CapturingGroup: 'CapturingGroup',\n  Character: 'Character',\n  CharacterClass: 'CharacterClass',\n  CharacterClassIntersection: 'CharacterClassIntersection',\n  CharacterClassRange: 'CharacterClassRange',\n  CharacterSet: 'CharacterSet',\n  Directive: 'Directive',\n  Flags: 'Flags',\n  Group: 'Group',\n  Pattern: 'Pattern',\n  Quantifier: 'Quantifier',\n  Regex: 'Regex',\n  Subroutine: 'Subroutine',\n  VariableLengthCharacterSet: 'VariableLengthCharacterSet',\n  // Used only by the transformer for Regex+ ASTs\n  Recursion: 'Recursion',\n};\n\nconst AstTypeAliases = {\n  AnyGroup: 'AnyGroup',\n  AnyNode: 'AnyNode',\n};\n\nfunction getAstTypeAliases(node) {\n  const {type} = node;\n  const types = [AstTypeAliases.AnyNode];\n  if (isLookaround(node) || type === AstTypes.CapturingGroup || type === AstTypes.Group) {\n    types.push(AstTypeAliases.AnyGroup);\n  }\n  types.push(type);\n  return types;\n}\n\nconst AstAssertionKinds = {\n  line_end: 'line_end',\n  line_start: 'line_start',\n  lookahead: 'lookahead',\n  lookbehind: 'lookbehind',\n  search_start: 'search_start',\n  string_end: 'string_end',\n  string_end_newline: 'string_end_newline',\n  string_start: 'string_start',\n  word_boundary: 'word_boundary',\n};\n\n// Identical values\nconst AstCharacterSetKinds = TokenCharacterSetKinds;\nconst AstDirectiveKinds = TokenDirectiveKinds;\n\nconst AstVariableLengthCharacterSetKinds = {\n  grapheme: 'grapheme',\n  newline: 'newline',\n};\n\n/**\n@typedef {{\n  type: 'Regex';\n  parent: null;\n  pattern: Object;\n  flags: Object;\n}} OnigurumaAst\n*/\n/**\n@param {import('./tokenize.js').TokenizerResult} tokenizerResult\n@param {{\n  skipBackrefValidation?: boolean;\n  skipPropertyNameValidation?: boolean;\n  verbose?: boolean;\n}} [options]\n@returns {OnigurumaAst}\n*/\nfunction parse({tokens, flags}, options) {\n  const opts = {\n    skipBackrefValidation: false,\n    skipPropertyNameValidation: false,\n    verbose: false,\n    ...options,\n  };\n  const context = {\n    capturingGroups: [],\n    current: 0,\n    hasNumberedRef: false,\n    namedGroupsByName: new Map(),\n    parent: null,\n    skipBackrefValidation: opts.skipBackrefValidation,\n    skipPropertyNameValidation: opts.skipPropertyNameValidation,\n    subroutines: [],\n    token: null,\n    tokens,\n    verbose: opts.verbose,\n    walk,\n  };\n  function walk(parent, state) {\n    const token = tokens[context.current];\n    context.parent = parent;\n    context.token = token;\n    // Advance for the next iteration\n    context.current++;\n    switch (token.type) {\n      case TokenTypes.Alternator:\n        // Top-level only; groups handle their own alternators\n        return createAlternative();\n      case TokenTypes.Assertion:\n        return createAssertionFromToken(token);\n      case TokenTypes.Backreference:\n        return parseBackreference(context);\n      case TokenTypes.Character:\n        return createCharacter(token.value);\n      case TokenTypes.CharacterClassHyphen:\n        return parseCharacterClassHyphen(context, state);\n      case TokenTypes.CharacterClassOpen:\n        return parseCharacterClassOpen(context, state);\n      case TokenTypes.CharacterSet:\n        return parseCharacterSet(context);\n      case TokenTypes.Directive:\n        return createDirectiveFromToken(token);\n      case TokenTypes.GroupOpen:\n        return parseGroupOpen(context, state);\n      case TokenTypes.Quantifier:\n        return parseQuantifier(context);\n      case TokenTypes.Subroutine:\n        return parseSubroutine(context);\n      case TokenTypes.VariableLengthCharacterSet:\n        return createVariableLengthCharacterSet(token.kind);\n      default:\n        throw new Error(`Unexpected token type \"${token.type}\"`);\n    }\n  }\n  const ast = createRegex(createPattern(), createFlags(flags));\n  let top = ast.pattern.alternatives[0];\n  while (context.current < tokens.length) {\n    const node = walk(top, {});\n    if (node.type === AstTypes.Alternative) {\n      ast.pattern.alternatives.push(node);\n      top = node;\n    } else {\n      top.elements.push(node);\n    }\n  }\n  // `context` updated by preceding `walk` loop\n  const {capturingGroups, hasNumberedRef, namedGroupsByName, subroutines} = context;\n  // Validation that requires knowledge about the complete pattern\n  if (hasNumberedRef && namedGroupsByName.size) {\n    throw new Error('Numbered backref/subroutine not allowed when using named capture');\n  }\n  for (const {ref} of subroutines) {\n    if (typeof ref === 'number') {\n      // Relative nums are already resolved\n      if (ref > capturingGroups.length) {\n        throw new Error(`Subroutine uses a group number that's not defined`);\n      }\n    } else if (!namedGroupsByName.has(ref)) {\n      throw new Error(r`Subroutine uses a group name that's not defined \"\\g<${ref}>\"`);\n    } else if (namedGroupsByName.get(ref).length > 1) {\n      throw new Error(r`Subroutine uses a duplicate group name \"\\g<${ref}>\"`);\n    }\n  }\n  // Add `parent` properties now that we have a final AST\n  traverse({node: ast}, null, {\n    AnyNode({node, parent}) {\n      node.parent = parent;\n    },\n  });\n  return ast;\n}\n\n// Supported (if the backref appears to the right of the reffed capture's opening paren):\n// - `\\k<name>`, `\\k'name'`\n// - When named capture not used:\n//   - `\\n`, `\\nn`, `\\nnn`\n//   - `\\k<n>`, `\\k'n'\n//   - `\\k<-n>`, `\\k'-n'`\n// Unsupported:\n// - `\\k<+n>`, `\\k'+n'` - Note that, Unlike Oniguruma, Onigmo doesn't support this as special\n//   syntax and therefore considers it a valid group name.\n// - Backref with recursion level (with num or name): `\\k<n+level>`, `\\k<n-level>`, etc.\n//   (Onigmo also supports `\\k<-n+level>`, `\\k<-n-level>`, etc.)\n// Backrefs in Onig use multiplexing for duplicate group names (the rules can be complicated when\n// overlapping with subroutines), but a `Backreference`'s simple `ref` prop doesn't capture these\n// details so multiplexed ref pointers need to be derived when working with the AST\nfunction parseBackreference(context) {\n  const {raw} = context.token;\n  const hasKWrapper = /^\\\\k[<']/.test(raw);\n  const ref = hasKWrapper ? raw.slice(3, -1) : raw.slice(1);\n  const fromNum = (num, isRelative = false) => {\n    const numCapturesToLeft = context.capturingGroups.length;\n    let orphan = false;\n    // Note: It's not an error for numbered backrefs to come before their referenced group in Onig,\n    // but an error is the best path for this library because:\n    // 1. Most placements are mistakes and can never match (based on the Onig behavior for backrefs\n    //    to nonparticipating groups).\n    // 2. Erroring matches the behavior of named backrefs.\n    // 3. The edge cases where they're matchable rely on rules for backref resetting within\n    //    quantified groups that are different in JS and aren't emulatable. Note that it's not a\n    //    backref in the first place if using `\\10` or higher and not as many capturing groups are\n    //    defined to the left (it's an octal or identity escape).\n    // [TODO] Ideally this would be refactored to include the backref in the AST when it's not an\n    // error in Onig (due to the reffed group being defined to the right), and the error handling\n    // would move to the transformer\n    if (num > numCapturesToLeft) {\n      // [WARNING] Skipping the error breaks assumptions and might create edge case issues, since\n      // backrefs are required to come after their captures; unfortunately this option is needed\n      // for TextMate grammars\n      if (context.skipBackrefValidation) {\n        orphan = true;\n      } else {\n        throw new Error(`Not enough capturing groups defined to the left \"${raw}\"`);\n      }\n    }\n    context.hasNumberedRef = true;\n    return createBackreference(isRelative ? numCapturesToLeft + 1 - num : num, {orphan});\n  };\n  if (hasKWrapper) {\n    const numberedRef = /^(?<sign>-?)0*(?<num>[1-9]\\d*)$/.exec(ref);\n    if (numberedRef) {\n      return fromNum(+numberedRef.groups.num, !!numberedRef.groups.sign);\n    }\n    // Invalid in a backref name even when valid in a group name\n    if (/[-+]/.test(ref)) {\n      throw new Error(`Invalid backref name \"${raw}\"`);\n    }\n    if (!context.namedGroupsByName.has(ref)) {\n      throw new Error(`Group name not defined to the left \"${raw}\"`);\n    }\n    return createBackreference(ref);\n  }\n  return fromNum(+ref);\n}\n\nfunction parseCharacterClassHyphen(context, state) {\n  const {parent, tokens, walk} = context;\n  const prevSiblingNode = parent.elements.at(-1);\n  const nextToken = tokens[context.current];\n  if (\n    prevSiblingNode &&\n    prevSiblingNode.type !== AstTypes.CharacterClass &&\n    prevSiblingNode.type !== AstTypes.CharacterClassRange &&\n    nextToken &&\n    nextToken.type !== TokenTypes.CharacterClassOpen &&\n    nextToken.type !== TokenTypes.CharacterClassClose &&\n    nextToken.type !== TokenTypes.CharacterClassIntersector\n  ) {\n    const nextNode = walk(parent, state);\n    if (prevSiblingNode.type === AstTypes.Character && nextNode.type === AstTypes.Character) {\n      parent.elements.pop();\n      return createCharacterClassRange(prevSiblingNode, nextNode);\n    }\n    throw new Error('Invalid character class range');\n  }\n  // Literal hyphen\n  return createCharacter(45);\n}\n\nfunction parseCharacterClassOpen(context, state) {\n  const {token, tokens, verbose, walk} = context;\n  let node = createCharacterClass({negate: token.negate});\n  const intersection = node.elements[0];\n  let nextToken = throwIfUnclosedCharacterClass(tokens[context.current]);\n  while (nextToken.type !== TokenTypes.CharacterClassClose) {\n    if (nextToken.type === TokenTypes.CharacterClassIntersector) {\n      intersection.classes.push(createCharacterClass({negate: false, baseOnly: true}));\n      // Skip the intersector\n      context.current++;\n    } else {\n      const cc = intersection.classes.at(-1);\n      cc.elements.push(walk(cc, state));\n    }\n    nextToken = throwIfUnclosedCharacterClass(tokens[context.current]);\n  }\n  if (!verbose) {\n    optimizeCharacterClassIntersection(intersection);\n  }\n  // Simplify tree if we don't need the intersection wrapper\n  if (intersection.classes.length === 1) {\n    const cc = intersection.classes[0];\n    // Only needed if `!verbose`; otherwise an intersection's direct kids are never negated\n    cc.negate = node.negate !== cc.negate;\n    node = cc;\n  }\n  // Skip the closing square bracket\n  context.current++;\n  return node;\n}\n\nfunction parseCharacterSet({token, skipPropertyNameValidation}) {\n  let {kind, negate, value} = token;\n  if (kind === TokenCharacterSetKinds.property) {\n    const normalized = slug(value);\n    if (PosixProperties.has(normalized)) {\n      kind = TokenCharacterSetKinds.posix;\n      value = normalized;\n    } else {\n      return createUnicodeProperty(value, {\n        negate,\n        skipPropertyNameValidation,\n      });\n    }\n  }\n  const node = {\n    type: AstTypes.CharacterSet,\n    kind: throwIfNot(AstCharacterSetKinds[kind], `Unexpected character set kind \"${kind}\"`),\n  };\n  if (\n    kind === TokenCharacterSetKinds.digit ||\n    kind === TokenCharacterSetKinds.hex ||\n    kind === TokenCharacterSetKinds.posix ||\n    kind === TokenCharacterSetKinds.space ||\n    kind === TokenCharacterSetKinds.word\n  ) {\n    node.negate = negate;\n    if (kind === TokenCharacterSetKinds.posix) {\n      node.value = value;\n    }\n  }\n  return node;\n}\n\nfunction parseGroupOpen(context, state) {\n  const {token, tokens, capturingGroups, namedGroupsByName, verbose, walk} = context;\n  let node = createByGroupKind(token);\n  // Track capturing group details for backrefs and subroutines (before parsing the group's\n  // contents so nested groups with the same name are tracked in order)\n  if (node.type === AstTypes.CapturingGroup) {\n    capturingGroups.push(node);\n    if (node.name) {\n      getOrCreate(namedGroupsByName, node.name, []).push(node);\n    }\n  }\n  let nextToken = throwIfUnclosedGroup(tokens[context.current]);\n  while (nextToken.type !== TokenTypes.GroupClose) {\n    if (nextToken.type === TokenTypes.Alternator) {\n      node.alternatives.push(createAlternative());\n      // Skip the alternator\n      context.current++;\n    } else {\n      const alt = node.alternatives.at(-1);\n      alt.elements.push(walk(alt, state));\n    }\n    nextToken = throwIfUnclosedGroup(tokens[context.current]);\n  }\n  if (!verbose) {\n    node = getOptimizedGroup(node);\n  }\n  // Skip the closing parenthesis\n  context.current++;\n  return node;\n}\n\nfunction parseQuantifier({token, parent}) {\n  const {min, max, greedy, possessive} = token;\n  const quantifiedNode = parent.elements.at(-1);\n  if (\n    !quantifiedNode ||\n    quantifiedNode.type === AstTypes.Assertion ||\n    quantifiedNode.type === AstTypes.Directive\n  ) {\n    throw new Error(`Quantifier requires a repeatable token`);\n  }\n  const node = createQuantifier(quantifiedNode, min, max, greedy, possessive);\n  parent.elements.pop();\n  return node;\n}\n\n// Onig subroutine behavior:\n// - Subroutines can appear before the groups they reference; ex: `\\g<1>(a)` is valid.\n// - Multiple subroutines can reference the same group.\n// - Subroutines can reference groups that themselves contain subroutines, followed to any depth.\n// - Subroutines can be used recursively, and `\\g<0>` recursively references the whole pattern.\n// - Subroutines can use relative references (backward or forward); ex: `\\g<+1>(.)\\g<-1>`.\n// - Subroutines don't get their own capturing group numbers; ex: `(.)\\g<1>\\2` is invalid.\n// - Subroutines use the flags that apply to their referenced group, so e.g.\n//   `(?-i)(?<a>a)(?i)\\g<a>` is fully case sensitive.\n// - Differences from PCRE/Perl/Regex+ subroutines:\n//   - Subroutines can't reference duplicate group names (though duplicate names are valid if no\n//     subroutines reference them).\n//   - Subroutines can't use absolute or relative numbers if named capture is used anywhere.\n//   - Named backrefs must be to the right of their group definition, so the backref in\n//     `\\g<a>\\k<a>(?<a>)` is invalid (not directly related to subroutines).\n//   - Subroutines don't restore capturing group match values (for backrefs) upon exit, so e.g.\n//     `(?<a>(?<b>[ab]))\\g<a>\\k<b>` matches `abb` but not `aba`; same for numbered.\n// The interaction of backref multiplexing (an Onig-specific feature) and subroutines is complex:\n// - Only the most recent value matched by a capturing group and its subroutines is considered for\n//   backref multiplexing, and this also applies to capturing groups nested within a group that's\n//   referenced by a subroutine.\n// - Although a subroutine can't reference a group with a duplicate name, it can reference a group\n//   with a nested capture whose name is duplicated (e.g. outside of the referenced group).\n//   - These duplicate names can then multiplex; but only the most recent value matched from within\n//     the outer group (or the subroutines that reference it) is available for multiplexing.\n//   - Ex: With `(?<a>(?<b>[123]))\\g<a>\\g<a>(?<b>0)\\k<b>`, the backref `\\k<b>` can only match `0`\n//     or whatever was matched by the most recently matched subroutine. If you took out `(?<b>0)`,\n//     no multiplexing would occur.\nfunction parseSubroutine(context) {\n  const {token, capturingGroups, subroutines} = context;\n  let ref = token.raw.slice(3, -1);\n  const numberedRef = /^(?<sign>[-+]?)0*(?<num>[1-9]\\d*)$/.exec(ref);\n  if (numberedRef) {\n    const num = +numberedRef.groups.num;\n    const numCapturesToLeft = capturingGroups.length;\n    context.hasNumberedRef = true;\n    ref = {\n      '': num,\n      '+': numCapturesToLeft + num,\n      '-': numCapturesToLeft + 1 - num,\n    }[numberedRef.groups.sign];\n    if (ref < 1) {\n      throw new Error('Invalid subroutine number');\n    }\n  // Special case for full-pattern recursion; can't be `+0`, `-0`, `00`, etc.\n  } else if (ref === '0') {\n    ref = 0;\n  }\n  const node = createSubroutine(ref);\n  subroutines.push(node);\n  return node;\n}\n\nfunction createAlternative() {\n  return {\n    type: AstTypes.Alternative,\n    elements: [],\n  };\n}\n\nfunction createAssertionFromToken({type, kind, negate}) {\n  if (type === TokenTypes.GroupOpen) {\n    return createLookaround({\n      behind: kind === TokenGroupKinds.lookbehind,\n      negate,\n    });\n  }\n  const nodeKind = throwIfNot({\n    '^': AstAssertionKinds.line_start,\n    '$': AstAssertionKinds.line_end,\n    '\\\\A': AstAssertionKinds.string_start,\n    '\\\\b': AstAssertionKinds.word_boundary,\n    '\\\\B': AstAssertionKinds.word_boundary,\n    '\\\\G': AstAssertionKinds.search_start,\n    '\\\\z': AstAssertionKinds.string_end,\n    '\\\\Z': AstAssertionKinds.string_end_newline,\n  }[kind], `Unexpected assertion kind \"${kind}\"`);\n  const node = {\n    type: AstTypes.Assertion,\n    kind: nodeKind,\n  };\n  if (nodeKind === AstAssertionKinds.word_boundary) {\n    node.negate = kind === r`\\B`;\n  }\n  return node;\n}\n\nfunction createBackreference(ref, options) {\n  const orphan = !!options?.orphan;\n  return {\n    type: AstTypes.Backreference,\n    ...(orphan && {orphan}),\n    ref,\n  };\n}\n\nfunction createByGroupKind(token) {\n  const {kind, number, name, flags} = token;\n  switch (kind) {\n    case TokenGroupKinds.atomic:\n      return createGroup({atomic: true});\n    case TokenGroupKinds.capturing:\n      return createCapturingGroup(number, name);\n    case TokenGroupKinds.group:\n      return createGroup({flags});\n    case TokenGroupKinds.lookahead:\n    case TokenGroupKinds.lookbehind:\n      return createAssertionFromToken(token);\n    default:\n      throw new Error(`Unexpected group kind \"${kind}\"`);\n  }\n}\n\nfunction createCapturingGroup(number, name) {\n  const hasName = name !== undefined;\n  if (hasName && !isValidGroupNameOniguruma(name)) {\n    throw new Error(`Group name \"${name}\" invalid in Oniguruma`);\n  }\n  return {\n    type: AstTypes.CapturingGroup,\n    number,\n    ...(hasName && {name}),\n    alternatives: [createAlternative()],\n  };\n}\n\nfunction createCharacter(charCode) {\n  return {\n    type: AstTypes.Character,\n    value: charCode,\n  };\n}\n\nfunction createCharacterClass(options) {\n  const opts = {\n    baseOnly: false,\n    negate: false,\n    ...options,\n  };\n  return {\n    type: AstTypes.CharacterClass,\n    negate: opts.negate,\n    elements: opts.baseOnly ? [] : [createCharacterClassIntersection()],\n  };\n}\n\nfunction createCharacterClassIntersection() {\n  return {\n    type: AstTypes.CharacterClassIntersection,\n    classes: [createCharacterClass({negate: false, baseOnly: true})],\n  };\n}\n\nfunction createCharacterClassRange(min, max) {\n  if (max.value < min.value) {\n    throw new Error('Character class range out of order');\n  }\n  return {\n    type: AstTypes.CharacterClassRange,\n    min,\n    max,\n  };\n}\n\nfunction createDirectiveFromToken({kind, flags}) {\n  const node = {\n    type: AstTypes.Directive,\n    kind: throwIfNot(AstDirectiveKinds[kind], `Unexpected directive kind \"${kind}\"`),\n  };\n  // Can't optimize by simply creating a `Group` with a `flags` prop and wrapping the remainder of\n  // the open group or pattern in it, because the flag modifier's effect might extend across\n  // alternation. Ex: `a(?i)b|c` is equivalent to `a(?i:b)|(?i:c)`, not `a(?i:b|c)`\n  if (kind === TokenDirectiveKinds.flags) {\n    node.flags = flags;\n  }\n  return node;\n}\n\nfunction createFlags({ignoreCase, dotAll, extended}) {\n  return {\n    type: AstTypes.Flags,\n    ignoreCase,\n    dotAll,\n    extended,\n  };\n}\n\nfunction createGroup(options) {\n  const atomic = options?.atomic;\n  const flags = options?.flags;\n  return {\n    type: AstTypes.Group,\n    ...(atomic && {atomic}),\n    ...(flags && {flags}),\n    alternatives: [createAlternative()],\n  };\n}\n\nfunction createLookaround(options) {\n  const opts = {\n    behind: false,\n    negate: false,\n    ...options,\n  };\n  return {\n    type: AstTypes.Assertion,\n    kind: opts.behind ? AstAssertionKinds.lookbehind : AstAssertionKinds.lookahead,\n    negate: opts.negate,\n    alternatives: [createAlternative()],\n  };\n}\n\nfunction createPattern() {\n  return {\n    type: AstTypes.Pattern,\n    alternatives: [createAlternative()],\n  };\n}\n\nfunction createQuantifier(element, min, max, greedy, possessive) {\n  // Could be checked in the tokenizer, but done here to parallel char class range validation and\n  // to prevent manually creating invalid quantifiers\n  if (max < min) {\n    throw new Error('Quantifier range out of order');\n  }\n  const node = {\n    type: AstTypes.Quantifier,\n    min,\n    max,\n    greedy,\n    possessive,\n    element,\n  };\n  return node;\n}\n\nfunction createRegex(pattern, flags) {\n  return {\n    type: AstTypes.Regex,\n    pattern,\n    flags,\n  };\n}\n\nfunction createSubroutine(ref) {\n  return {\n    type: AstTypes.Subroutine,\n    ref,\n  };\n}\n\nfunction createUnicodeProperty(value, options) {\n  const opts = {\n    negate: false,\n    skipPropertyNameValidation: false,\n    ...options,\n  };\n  return {\n    type: AstTypes.CharacterSet,\n    kind: AstCharacterSetKinds.property,\n    value: opts.skipPropertyNameValidation ? value : getJsUnicodePropertyName(value),\n    negate: opts.negate,\n  }\n}\n\nfunction createVariableLengthCharacterSet(kind) {\n  return {\n    type: AstTypes.VariableLengthCharacterSet,\n    kind: throwIfNot({\n      '\\\\R': AstVariableLengthCharacterSetKinds.newline,\n      '\\\\X': AstVariableLengthCharacterSetKinds.grapheme,\n    }[kind], `Unexpected varcharset kind \"${kind}\"`),\n  };\n}\n\n// Unlike Onig, JS Unicode property names are case sensitive, don't ignore whitespace and\n// underscores, and require underscores in specific positions\nfunction getJsUnicodePropertyName(value) {\n  const slugged = slug(value);\n  if (JsUnicodePropertiesOfStringsMap.has(slugged)) {\n    // Variable-length properties of strings aren't supported by Onig\n    throw new Error(r`Unicode property \"\\p{${value}}\" unsupported in Oniguruma`);\n  }\n  const jsName = JsUnicodePropertiesMap.get(slugged);\n  if (jsName) {\n    return jsName;\n  }\n  // Assume it's a script name (avoids adding heavyweight data for the names); JS requires\n  // formatting 'Like_This', so use a best effort to reformat the name (covers everything sane, but\n  // not able to map for all possible formatting differences)\n  return value.\n    trim().\n    replace(/\\s+/g, '_').\n    replace(/[A-Z][a-z]+(?=[A-Z])/g, '$&_'). // `PropertyName` to `Property_Name`\n    replace(/[A-Za-z]+/g, m => m[0].toUpperCase() + m.slice(1).toLowerCase());\n}\n\n// If a direct child group is needlessly nested, return it instead (after modifying it)\nfunction getOptimizedGroup(node) {\n  const firstAltFirstEl = node.alternatives[0].elements[0];\n  if (\n    node.type === AstTypes.Group &&\n    hasOnlyChild(node, kid => kid.type === AstTypes.Group) &&\n    !(node.atomic && firstAltFirstEl.flags) &&\n    !(node.flags && (firstAltFirstEl.atomic || firstAltFirstEl.flags))\n  ) {\n    if (node.atomic) {\n      firstAltFirstEl.atomic = true;\n    } else if (node.flags) {\n      firstAltFirstEl.flags = node.flags;\n    }\n    return firstAltFirstEl;\n  }\n  return node;\n}\n\nfunction isLookaround({type, kind}) {\n  return type === AstTypes.Assertion &&\n    (kind === AstAssertionKinds.lookahead || kind === AstAssertionKinds.lookbehind);\n}\n\nfunction isValidGroupNameOniguruma(name) {\n  return !/^(?:[-\\d]|$)/.test(name);\n}\n\n// For any intersection classes that contain only a class, swap the parent with its (modded) child\nfunction optimizeCharacterClassIntersection(intersection) {\n  for (let i = 0; i < intersection.classes.length; i++) {\n    const cc = intersection.classes[i];\n    const firstChild = cc.elements[0];\n    if (cc.elements.length === 1 && firstChild.type === AstTypes.CharacterClass) {\n      intersection.classes[i] = firstChild;\n      firstChild.negate = cc.negate !== firstChild.negate;\n    }\n  }\n}\n\nfunction throwIfUnclosedCharacterClass(token) {\n  return throwIfNot(token, 'Unclosed character class');\n}\n\nfunction throwIfUnclosedGroup(token) {\n  return throwIfNot(token, 'Unclosed group');\n}\n\nexport {\n  AstAssertionKinds,\n  AstCharacterSetKinds,\n  AstDirectiveKinds,\n  AstTypes,\n  AstVariableLengthCharacterSetKinds,\n  createAlternative,\n  createBackreference,\n  createCapturingGroup,\n  createCharacter,\n  createCharacterClass,\n  createCharacterClassIntersection,\n  createCharacterClassRange,\n  createFlags,\n  createGroup,\n  createLookaround,\n  createPattern,\n  createQuantifier,\n  createRegex,\n  createSubroutine,\n  createUnicodeProperty,\n  createVariableLengthCharacterSet,\n  getAstTypeAliases,\n  isLookaround,\n  parse,\n};\n", "import {AstAssertionKinds, AstTypes, isLookaround} from './parse.js';\nimport {hasOnlyChild} from './utils.js';\n\n// Special case handling that requires coupling with a `RegExp` subclass (see `EmulatedRegExp`).\n// These changes add emulation support for some common patterns that are otherwise unsupportable.\n// Only one subclass strategy is supported per pattern\nfunction applySubclassStrategies(ast) {\n  const alts = ast.pattern.alternatives;\n  const firstEl = alts[0].elements[0];\n\n  if (alts.length > 1 || !firstEl) {\n    // These strategies only work if there's no top-level alternation\n    return null;\n  }\n\n  const hasWrapperGroup =\n    hasOnlyChild(ast.pattern, kid => (\n      kid.type === AstTypes.CapturingGroup || kid.type === AstTypes.Group\n    )) &&\n    firstEl.alternatives.length === 1;\n  const singleAltIn = hasWrapperGroup ? firstEl.alternatives[0] : alts[0];\n  // First el within first group if the group doesn't contain top-level alternation, else just the\n  // first el of the pattern; ex: a flag group might enclose the full pattern\n  const firstElIn = hasWrapperGroup ? singleAltIn.elements[0] : firstEl;\n  if (!firstElIn) {\n    return null;\n  }\n\n  // ## Strategy `line_or_search_start`: Support leading `(^|\\G)` and similar\n  if (\n    (firstElIn.type === AstTypes.CapturingGroup || firstElIn.type === AstTypes.Group) &&\n    firstElIn.alternatives.length === 2 &&\n    firstElIn.alternatives[0].elements.length === 1 &&\n    firstElIn.alternatives[1].elements.length === 1\n  ) {\n    const el1 = firstElIn.alternatives[0].elements[0];\n    const el2 = firstElIn.alternatives[1].elements[0];\n    if (\n      (el1.kind === AstAssertionKinds.line_start && el2.kind === AstAssertionKinds.search_start) ||\n      (el1.kind === AstAssertionKinds.search_start && el2.kind === AstAssertionKinds.line_start)\n    ) {\n      // Remove the `\\G` and its container alternative\n      if (el1.kind === AstAssertionKinds.line_start) {\n        firstElIn.alternatives.pop();\n      } else {\n        firstElIn.alternatives.shift();\n      }\n      return 'line_or_search_start';\n    }\n  }\n\n  // ## Strategy `not_search_start`: Support leading `(?!\\G)` and similar\n  if (isLoneGLookaround(firstElIn, {negate: true})) {\n    // Remove the `\\G` and its containing negative lookaround\n    firstElIn.parent.elements.shift();\n    return 'not_search_start';\n  }\n  for (let i = 0; i < singleAltIn.elements.length; i++) {\n    const el = singleAltIn.elements[i];\n    if (!isZeroLengthNode(el)) {\n      break;\n    }\n    if (isLoneGLookaround(el, {negate: true})) {\n      // Remove the `\\G` and its containing negative lookaround\n      singleAltIn.elements.splice(i, 1);\n      return 'not_search_start';\n    }\n  }\n\n  return null;\n}\n\nfunction isLoneGLookaround(node, options) {\n  return (\n    isLookaround(node) &&\n    node.negate === options.negate &&\n    hasOnlyChild(node, kid => kid.kind === AstAssertionKinds.search_start)\n  );\n}\n\nfunction isZeroLengthNode(node) {\n  return (\n    node.type === AstTypes.Assertion ||\n    node.type === AstTypes.Directive ||\n    (node.type === AstTypes.Quantifier && !node.min)\n  );\n}\n\nexport {\n  applySubclassStrategies,\n  isLoneGLookaround,\n  isZeroLengthNode,\n};\n", "const r = String.raw;\nconst seq = r`(?:\\p{Emoji}\\uFE0F\\u20E3?|\\p{Emoji_Modifier_Base}\\p{Emoji_Modifier}?|\\p{Emoji_Presentation})`;\nconst sTags = r`\\u{E0061}-\\u{E007A}`;\nexport default () => new RegExp(r`[\\u{1F1E6}-\\u{1F1FF}]{2}|\\u{1F3F4}[${sTags}]{2}[\\u{E0030}-\\u{E0039}${sTags}]{1,3}\\u{E007F}|${seq}(?:\\u200D${seq})*`, 'gu');\n", "import {Accuracy, Target} from './options.js';\nimport {AstAssertionKinds, AstCharacterSetKinds, AstDirectiveKinds, AstTypes, AstVariableLengthCharacterSetKinds, createAlternative, createBackreference, createCapturingGroup, createGroup, createLookaround, createUnicodeProperty, isLookaround, parse} from './parse.js';\nimport {applySubclassStrategies, isLoneGLookaround, isZeroLengthNode} from './subclass-strategies.js';\nimport {tokenize} from './tokenize.js';\nimport {traverse} from './traverse.js';\nimport {JsUnicodeProperties, PosixClassesMap} from './unicode.js';\nimport {cp, getNewCurrentFlags, getOrCreate, isMinTarget, r} from './utils.js';\nimport emojiRegex from 'emoji-regex-xs';\n\n/**\n@typedef {{\n  type: 'Regex';\n  parent: null;\n  pattern: Object;\n  flags: Object;\n  options: Object;\n  _strategy?: string;\n}} RegexAst\n*/\n/**\nTransforms an Oniguruma AST in-place to a [Regex+](https://github.com/slevithan/regex) AST.\nAssumes target ES2025, expecting the generator to down-convert to the desired JS target version.\n\nRegex+'s syntax and behavior is a strict superset of native JavaScript, so the AST is very close\nto representing native ES2025 `RegExp` but with some added features (atomic groups, possessive\nquantifiers, recursion). The AST doesn't use some of Regex+'s extended features like flag x or\nsubroutines because they follow PCRE behavior and work somewhat differently than in Oniguruma. The\nAST represents what's needed to precisely reproduce Oniguruma behavior using Regex+.\n@param {import('./parse.js').OnigurumaAst} ast\n@param {{\n  accuracy?: keyof Accuracy;\n  avoidSubclass?: boolean;\n  bestEffortTarget?: keyof Target;\n}} [options]\n@returns {RegexAst}\n*/\nfunction transform(ast, options) {\n  const opts = {\n    // A couple edge cases exist where options `accuracy` and `bestEffortTarget` are used:\n    // - `VariableLengthCharacterSet` kind `grapheme` (`\\X`): An exact representation would require\n    //   heavy Unicode data; a best-effort approximation requires knowing the target.\n    // - `CharacterSet` kind `posix` with values `graph` and `print`: Their complex exact\n    //   representations are hard to change after the fact in the generator to a best-effort\n    //   approximation based on the target, so produce the appropriate structure here.\n    accuracy: 'default',\n    avoidSubclass: false,\n    bestEffortTarget: 'ES2025',\n    ...options,\n  };\n  // AST transformations that work together with a `RegExp` subclass to add advanced emulation\n  const strategy = opts.avoidSubclass ? null : applySubclassStrategies(ast);\n  const firstPassState = {\n    accuracy: opts.accuracy,\n    flagDirectivesByAlt: new Map(),\n    minTargetEs2024: isMinTarget(opts.bestEffortTarget, 'ES2024'),\n    // Subroutines can appear before the groups they ref, so collect reffed nodes for a second pass \n    subroutineRefMap: new Map(),\n    supportedGNodes: new Set(),\n  };\n  traverse({node: ast}, firstPassState, FirstPassVisitor);\n  // Global flags modified by the first pass\n  const globalFlags = {\n    dotAll: ast.flags.dotAll,\n    ignoreCase: ast.flags.ignoreCase,\n  };\n  // The interplay of subroutines (with Onig's unique rules/behavior for them; see comments in the\n  // parser for details) with backref multiplexing (a unique Onig feature), flag modifiers, and\n  // duplicate group names (which might be indirectly referenced by subroutines even though\n  // subroutines can't directly reference duplicate names) is extremely complicated to emulate in\n  // JS in a way that handles all edge cases, so we need multiple passes to do it\n  const secondPassState = {\n    currentFlags: globalFlags,\n    prevFlags: null,\n    globalFlags,\n    groupOriginByCopy: new Map(),\n    groupsByName: new Map(),\n    multiplexCapturesToLeftByRef: new Map(),\n    openRefs: new Map(),\n    reffedNodesByReferencer: new Map(),\n    subroutineRefMap: firstPassState.subroutineRefMap,\n  };\n  traverse({node: ast}, secondPassState, SecondPassVisitor);\n  const thirdPassState = {\n    groupsByName: secondPassState.groupsByName,\n    highestOrphanBackref: 0,\n    numCapturesToLeft: 0,\n    reffedNodesByReferencer: secondPassState.reffedNodesByReferencer,\n  };\n  traverse({node: ast}, thirdPassState, ThirdPassVisitor);\n  if (strategy) {\n    ast._strategy = strategy;\n  }\n  return ast;\n}\n\nconst FirstPassVisitor = {\n  Alternative: {\n    enter({node, parent, key}, {flagDirectivesByAlt}) {\n      // Look for own-level flag directives when entering an alternative because after traversing\n      // the directive itself, any subsequent flag directives will no longer be at the same level\n      const flagDirectives = node.elements.filter(el => el.kind === AstDirectiveKinds.flags);\n      for (let i = key + 1; i < parent.alternatives.length; i++) {\n        const forwardSiblingAlt = parent.alternatives[i];\n        getOrCreate(flagDirectivesByAlt, forwardSiblingAlt, []).push(...flagDirectives);\n      }\n    },\n    exit({node}, {flagDirectivesByAlt}) {\n      // Wait until exiting to wrap an alternative's nodes with flag groups that extend flag\n      // directives from prior sibling alternatives because doing this at the end allows inner\n      // nodes to accurately check their level in the tree\n      if (flagDirectivesByAlt.get(node)?.length) {\n        const flags = getCombinedFlagModsFromFlagNodes(flagDirectivesByAlt.get(node));\n        if (flags) {\n          const flagGroup = prepContainer(createGroup({flags}), node.elements);\n          // Manually set the parent since we're not using `replaceWith`\n          flagGroup.parent = node;\n          node.elements = [flagGroup];\n        }\n      }\n    },\n  },\n\n  Assertion({node, ast, remove, replaceWith}, {accuracy, supportedGNodes}) {\n    const {kind, negate} = node;\n    if (kind === AstAssertionKinds.line_end) {\n      // Onig's only line break char is line feed, unlike JS\n      replaceWith(parseFragment(r`(?=\\z|\\n)`));\n    } else if (kind === AstAssertionKinds.line_start) {\n      // Onig's only line break char is line feed, unlike JS\n      replaceWith(parseFragment(r`(?<=\\A|\\n)`));\n    } else if (kind === AstAssertionKinds.search_start) {\n      if (!supportedGNodes.has(node) && accuracy !== 'loose') {\n        throw new Error(r`Uses \"\\G\" in a way that's unsupported`);\n      }\n      ast.flags.sticky = true;\n      remove();\n    } else if (kind === AstAssertionKinds.string_end_newline) {\n      replaceWith(parseFragment(r`(?=\\n?\\z)`));\n    } else if (kind === AstAssertionKinds.word_boundary) {\n      // Onig's word char definition for `\\b` is different than for `\\w`\n      const wordChar = r`[\\p{L}\\p{N}\\p{Pc}]`;\n      const b = `(?:(?<=${wordChar})(?!${wordChar})|(?<!${wordChar})(?=${wordChar}))`;\n      const B = `(?:(?<=${wordChar})(?=${wordChar})|(?<!${wordChar})(?!${wordChar}))`;\n      replaceWith(parseFragment(negate ? B : b));\n    }\n    // Kinds `string_end` and `string_start` don't need transformation since JS flag m isn't used.\n    // Kinds `lookahead` and `lookbehind` also don't need transformation\n  },\n\n  CapturingGroup({node}, {subroutineRefMap}) {\n    const {name, number} = node;\n    if (name && !isValidGroupNameJs(name)) {\n      throw new Error(`Group name \"${name}\" invalid in JS`);\n    }\n    subroutineRefMap.set(name ?? number, node);\n  },\n\n  CharacterSet({node, replaceWith}, {accuracy, minTargetEs2024}) {\n    const {kind, negate, value} = node;\n    if (kind === AstCharacterSetKinds.any) {\n      replaceWith(createUnicodeProperty('Any'));\n    } else if (kind === AstCharacterSetKinds.hex) {\n      replaceWith(createUnicodeProperty('AHex', {negate}));\n    } else if (kind === AstCharacterSetKinds.non_newline) {\n      replaceWith(parseFragment(r`[^\\n]`));\n    } else if (kind === AstCharacterSetKinds.posix) {\n      if (!minTargetEs2024 && (value === 'graph' || value === 'print')) {\n        if (accuracy === 'strict') {\n          throw new Error(`POSIX class \"${value}\" requires min target ES2024 or non-strict accuracy`);\n        }\n        let ascii = {\n          graph: '!-~',\n          print: ' -~',\n        }[value];\n        if (negate) {\n          // POSIX classes are always nested in a char class; manually invert the range rather than\n          // using `[^...]` so it can be unwrapped, since ES2018 doesn't support nested classes\n          ascii = `\\0-${cp(ascii.codePointAt(0) - 1)}${cp(ascii.codePointAt(2) + 1)}-\\u{10FFFF}`;\n        }\n        replaceWith(parseFragment(`[${ascii}]`));\n      } else {\n        const negateableNode = parseFragment(PosixClassesMap.get(value));\n        negateableNode.negate = negate;\n        replaceWith(negateableNode);\n      }\n    } else if (kind === AstCharacterSetKinds.property) {\n      if (!JsUnicodeProperties.has(value)) {\n        // Assume it's a script\n        node.key = 'sc';\n      }\n    } else if (kind === AstCharacterSetKinds.space) {\n      // Unlike JS, Onig's `\\s` matches only ASCII tab, space, LF, VT, FF, and CR\n      const s = parseFragment('[ \\t\\n\\v\\f\\r]');\n      s.negate = negate;\n      replaceWith(s);\n    }\n  },\n\n  Directive(path, state) {\n    const {node, parent, ast, remove, replaceWith, removeAllPrevSiblings, removeAllNextSiblings} = path;\n    const {kind, flags} = node;\n    if (kind === AstDirectiveKinds.flags) {\n      if (!flags.enable && !flags.disable) {\n        // Flag directive without flags; ex: `(?-)`, `(?--)`\n        remove();\n      } else {\n        const flagGroup = prepContainer(createGroup({flags}), removeAllNextSiblings());\n        replaceWith(flagGroup);\n        traverseReplacement(flagGroup, path, state, FirstPassVisitor);\n      }\n    } else if (kind === AstDirectiveKinds.keep) {\n      // Allows multiple `\\K`s\n      if (parent.parent !== ast.pattern || ast.pattern.alternatives.length > 1) {\n        // `\\K` is emulatable at least within top-level alternation, but it's tricky. Ex: `ab\\Kc|a`\n        // is equivalent to `(?<=ab)c|a(?!bc)`, not simply `(?<=ab)c|a`\n        throw new Error(r`Uses \"\\K\" in a way that's unsupported`);\n      }\n      replaceWith(prepContainer(createLookaround({behind: true}), removeAllPrevSiblings()));\n    }\n  },\n\n  Flags({node, parent}) {\n    // Onig's flag x (`extended`) isn't available in JS\n    delete node.extended;\n    Object.assign(node, {\n      // JS flag g; no Onig equiv\n      global: false,\n      // JS flag d; no Onig equiv\n      hasIndices: false,\n      // JS flag m; no Onig equiv but its behavior is always on in Onig. Onig's only line break\n      // char is line feed, unlike JS, so this flag isn't used since it would produce inaccurate\n      // results (also allows `^` and `$` to be used in the generator for string start and end)\n      multiline: false,\n      // JS flag y; no Onig equiv, but used for `\\G` emulation\n      sticky: node.sticky ?? false,\n      // Note: Regex+ doesn't allow explicitly adding flags it handles implicitly, so leave out\n      // properties `unicode` (JS flag u) and `unicodeSets` (JS flag v). Keep the existing values\n      // for `ignoreCase` (flag i) and `dotAll` (JS flag s, but Onig flag m)\n    });\n    // Options accepted by Regex+; see <github.com/slevithan/regex#-options>\n    parent.options = {\n      disable: {\n        // Onig uses different rules for flag x than Regex+, so disable the implicit flag\n        x: true,\n        // Onig has no flag to control \"named capture only\" mode but contextually applies its\n        // behavior when named capturing is used, so disable Regex+'s implicit flag for it\n        n: true,\n      },\n      force: {\n        // Always add flag v because we're generating an AST that relies on it (it enables JS\n        // support for Onig features nested classes, set intersection, Unicode properties, etc.).\n        // However, the generator might disable flag v based on its `target` option\n        v: true,\n      },\n    };\n  },\n\n  Group({node}) {\n    if (!node.flags) {\n      return;\n    }\n    const {enable, disable} = node.flags;\n    // Onig's flag x (`extended`) isn't available in JS\n    enable?.extended && delete enable.extended;\n    disable?.extended && delete disable.extended;\n    // JS doesn't support flag groups that enable and disable the same flag; ex: `(?i-i:)`\n    enable?.dotAll && disable?.dotAll && delete enable.dotAll;\n    enable?.ignoreCase && disable?.ignoreCase && delete enable.ignoreCase;\n    // Cleanup\n    enable && !Object.keys(enable).length && delete node.flags.enable;\n    disable && !Object.keys(disable).length && delete node.flags.disable;\n    !node.flags.enable && !node.flags.disable && delete node.flags;\n  },\n\n  Pattern({node}, {accuracy, supportedGNodes}) {\n    // For `\\G` to be accurately emulatable using JS flag y, it must be at (and only at) the start\n    // of every top-level alternative (with complex rules for what determines being at the start).\n    // Additional `\\G` error checking in `Assertion` visitor\n    const leadingGs = [];\n    let hasAltWithLeadG = false;\n    let hasAltWithoutLeadG = false;\n    for (const alt of node.alternatives) {\n      const leadingG = getLeadingG(alt.elements);\n      if (leadingG) {\n        hasAltWithLeadG = true;\n        Array.isArray(leadingG) ?\n          leadingGs.push(...leadingG) :\n          leadingGs.push(leadingG);\n      } else {\n        hasAltWithoutLeadG = true;\n      }\n    }\n    if (hasAltWithLeadG && hasAltWithoutLeadG && accuracy !== 'loose') {\n      throw new Error(r`Uses \"\\G\" in a way that's unsupported`);\n    }\n    // Supported `\\G` nodes will be removed when traversed; others will error if not `loose`\n    leadingGs.forEach(g => supportedGNodes.add(g))\n  },\n\n  Quantifier({node}) {\n    if (node.element.type === AstTypes.Quantifier) {\n      // Change e.g. `a**` to `(?:a*)*`\n      const group = prepContainer(createGroup(), [node.element]);\n      // Manually set the parent since we're not using `replaceWith`\n      group.parent = node;\n      node.element = group;\n    }\n  },\n\n  VariableLengthCharacterSet({node, replaceWith}, {accuracy, minTargetEs2024}) {\n    const {kind} = node;\n    if (kind === AstVariableLengthCharacterSetKinds.newline) {\n      replaceWith(parseFragment('(?>\\r\\n?|[\\n\\v\\f\\x85\\u2028\\u2029])'));\n    } else if (kind === AstVariableLengthCharacterSetKinds.grapheme) {\n      if (accuracy === 'strict') {\n        throw new Error(r`Use of \"\\X\" requires non-strict accuracy`);\n      }\n      // `emojiRegex` is more permissive than `\\p{RGI_Emoji}` since it allows over/under-qualified\n      // emoji using a general pattern that matches any Unicode sequence following the structure of\n      // a valid emoji. That actually makes it more accurate for matching any grapheme\n      const emoji = minTargetEs2024 ? r`\\p{RGI_Emoji}` : emojiRegex().source.replace(/\\\\u\\{/g, `\\\\x{`);\n      // Close approximation of an extended grapheme cluster. Details: <unicode.org/reports/tr29/>.\n      // Skip name check to allow `RGI_Emoji` through, which Onig doesn't support\n      replaceWith(parseFragment(r`(?>\\r\\n|${emoji}|\\P{M}\\p{M}*)`, {skipPropertyNameValidation: true}));\n    } else {\n      throw new Error(`Unexpected varcharset kind \"${kind}\"`);\n    }\n  },\n};\n\nconst SecondPassVisitor = {\n  Backreference({node}, {multiplexCapturesToLeftByRef, reffedNodesByReferencer}) {\n    const {orphan, ref} = node;\n    if (!orphan) {\n      // Copy the current state for later multiplexing expansion. It's done in a subsequent pass\n      // because backref numbers need to be recalculated after subroutine expansion\n      reffedNodesByReferencer.set(node, [...multiplexCapturesToLeftByRef.get(ref).map(({node}) => node)]);\n    }\n  },\n\n  Recursion({node}, {reffedNodesByReferencer}) {\n    // Recursion nodes are created during the current traversal; they're only traversed here if a\n    // recursion node created during traversal is then copied by a subroutine expansion, e.g. with\n    // `(?<a>\\g<a>)\\g<a>`\n    const {ref} = node;\n    // Immediate parent is an alternative or quantifier; can skip\n    let reffed = node.parent;\n    while ((reffed = reffed.parent)) {\n      if (reffed.type === AstTypes.CapturingGroup && (reffed.name === ref || reffed.number === ref)) {\n        break;\n      }\n    }\n    // Track the referenced node because `ref`s are rewritten in a subsequent pass; capturing group\n    // names and numbers might change due to subroutine expansion and duplicate group names\n    reffedNodesByReferencer.set(node, reffed);\n  },\n\n  CapturingGroup: {\n    enter(\n      { node,\n        replaceWith,\n        skip,\n      },\n      { groupOriginByCopy,\n        groupsByName,\n        multiplexCapturesToLeftByRef,\n        openRefs,\n        reffedNodesByReferencer,\n      }\n    ) {\n      // Has value if we're within a subroutine expansion\n      const origin = groupOriginByCopy.get(node);\n      const ref = node.name ?? node.number;\n\n      // ## Handle recursion; runs after subroutine expansion\n      if (origin && openRefs.has(ref)) {\n        // Recursion doesn't affect any following backrefs to its `ref` (unlike other subroutines),\n        // so don't wrap with a capture. The reffed group might have its name removed due to later\n        // subroutine expansion\n        const recursion = createRecursion(ref);\n        reffedNodesByReferencer.set(recursion, openRefs.get(ref));\n        replaceWith(recursion);\n        // This node's kids have been removed from the tree, so no need to traverse them\n        skip();\n        return;\n      }\n      // Name or number; not mixed since can't use numbered subroutines with named capture\n      openRefs.set(ref, node);\n\n      // ## Track data for backref multiplexing\n      const multiplexNodes = getOrCreate(multiplexCapturesToLeftByRef, ref, []);\n      for (let i = 0; i < multiplexNodes.length; i++) {\n        // Captures added via subroutine expansion (maybe indirectly because they were descendant\n        // captures of the reffed group or in a nested subroutine expansion) form a set with their\n        // origin group and any other copies of it added via subroutines. Only the most recently\n        // matched within this set is added to backref multiplexing. So search the list of already-\n        // tracked multiplexed nodes for this group name or number to see if there's a node being\n        // replaced by this capture\n        const multiplex = multiplexNodes[i];\n        if (\n          // This group is from subroutine expansion, and there's a multiplex value from either the\n          // origin node or a prior subroutine expansion group with the same origin\n          (origin === multiplex.node || (origin && origin === multiplex.origin)) ||\n          // This group is not from subroutine expansion, and it comes after a subroutine expansion\n          // group that refers to this group\n          node === multiplex.origin\n        ) {\n          multiplexNodes.splice(i, 1);\n          break;\n        }\n      }\n      multiplexNodes.push({node, origin});\n\n      // ## Track data for duplicate names within an alternation path\n      // Pre-ES2025 doesn't allow duplicate names, but ES2025+ allows duplicate names that are\n      // unique per mutually exclusive alternation path. So if using a duplicate name for this\n      // path, remove the name from all but the latest instance (also applies to groups added via\n      // subroutine expansion)\n      if (node.name) {\n        const groupsWithSameName = getOrCreate(groupsByName, node.name, new Map());\n        for (const groupInfo of groupsWithSameName.values()) {\n          if (!groupInfo.hasDuplicateNameToRemove && canParticipateWithNode(groupInfo.node, node, {\n            ancestorsParticipate: true,\n          })) {\n            // Will change the earlier instance with this name to an unnamed capture in a later pass\n            groupInfo.hasDuplicateNameToRemove = true;\n          }\n        }\n        groupsByName.get(node.name).set(node, {node});\n      }\n    },\n    exit({node}, {openRefs}) {\n      openRefs.delete(node.name ?? node.number);\n    },\n  },\n\n  Group: {\n    enter({node}, state) {\n      // Flag directives have already been converted to flag groups by the previous pass\n      state.prevFlags = state.currentFlags;\n      if (node.flags) {\n        state.currentFlags = getNewCurrentFlags(state.currentFlags, node.flags);\n      }\n    },\n    exit(_, state) {\n      state.currentFlags = state.prevFlags;\n    },\n  },\n\n  Subroutine(path, state) {\n    const {node, replaceWith} = path;\n    const {ref} = node;\n    const reffedGroupNode = state.subroutineRefMap.get(ref);\n    // Other forms of recursion are handled by the `CapturingGroup` visitor\n    const isGlobalRecursion = ref === 0;\n    const expandedSubroutine = isGlobalRecursion ?\n      createRecursion(ref) :\n      // The reffed group might itself contain subroutines, which are expanded during sub-traversal\n      cloneCapturingGroup(reffedGroupNode, state.groupOriginByCopy, null);\n    let replacement = expandedSubroutine;\n    if (!isGlobalRecursion) {\n      // Subroutines take their flags from the reffed group, not the flags surrounding themselves\n      const reffedGroupFlagMods = getCombinedFlagModsFromFlagNodes(getAllParents(reffedGroupNode, node => {\n        return node.type === AstTypes.Group && !!node.flags;\n      }));\n      const reffedGroupFlags = reffedGroupFlagMods ?\n        getNewCurrentFlags(state.globalFlags, reffedGroupFlagMods) :\n        state.globalFlags;\n      if (!areFlagsEqual(reffedGroupFlags, state.currentFlags)) {\n        replacement = prepContainer(createGroup({\n          flags: getFlagModsFromFlags(reffedGroupFlags),\n        }), [expandedSubroutine]);\n      }\n    }\n    replaceWith(replacement);\n    if (!isGlobalRecursion) {\n      traverseReplacement(replacement, path, state, SecondPassVisitor);\n    }\n  },\n};\n\nconst ThirdPassVisitor = {\n  Backreference({node, replaceWith}, state) {\n    if (node.orphan) {\n      state.highestOrphanBackref = Math.max(state.highestOrphanBackref, node.ref);\n      // Don't renumber; used with option `tmGrammar`\n      return;\n    }\n    const reffedNodes = state.reffedNodesByReferencer.get(node);\n    const participants = reffedNodes.filter(reffed => canParticipateWithNode(reffed, node, {\n      ancestorsParticipate: false,\n    }));\n    // For the backref's `ref`, use `number` rather than `name` because group names might have been\n    // removed if they're duplicates within their alternation path, or they might be removed later\n    // by the generator (depending on target) if they're duplicates within the overall pattern.\n    // Backrefs must come after groups they ref, so reffed node `number`s are already recalculated\n    if (!participants.length) {\n      // If no participating capture, convert backref to to `(?!)`; backrefs to nonparticipating\n      // groups can't match in Onig but match the empty string in JS\n      replaceWith(createLookaround({negate: true}));\n    } else if (participants.length > 1) {\n      // Multiplex\n      const alts = participants.map(reffed => adoptAndSwapKids(\n        createAlternative(),\n        [createBackreference(reffed.number)]\n      ));\n      replaceWith(adoptAndSwapKids(createGroup(), alts));\n    } else {\n      node.ref = participants[0].number;\n    }\n  },\n\n  CapturingGroup({node}, state) {\n    // Recalculate the number since the current value might be wrong due to subroutine expansion\n    node.number = ++state.numCapturesToLeft;\n    if (node.name) {\n      // Removing duplicate names here rather than in an earlier pass avoids extra complexity when\n      // handling subroutine expansion and backref multiplexing\n      if (state.groupsByName.get(node.name).get(node).hasDuplicateNameToRemove) {\n        delete node.name;\n      }\n    }\n  },\n\n  Recursion({node}, state) {\n    if (node.ref === 0) {\n      return;\n    }\n    // For the recursion's `ref`, use `number` rather than `name` because group names might have\n    // been removed if they're duplicates within their alternation path, or they might be removed\n    // later by the generator (depending on target) if they're duplicates within the overall\n    // pattern. Since recursion appears within the group it refs, the reffed node's `number` has\n    // already been recalculated\n    node.ref = state.reffedNodesByReferencer.get(node).number;\n  },\n\n  Regex: {\n    exit({node}, state) {\n      // [HACK] Add unnamed captures to the end of the regex if needed to allow orphaned backrefs\n      // to be valid in JS with flag u/v. This is needed to support TextMate grammars, which\n      // replace numbered backrefs in their `end` pattern with values matched by captures in their\n      // `begin` pattern! See <github.com/microsoft/vscode-textmate/blob/7e0ea282f4f25fef12a6c84fa4fa7266f67b58dc/src/rule.ts#L661-L663>\n      // An `end` pattern, prior to this substitution, might have backrefs to a group that doesn't\n      // exist within `end`. This presents a dilemma since both Oniguruma and JS (with flag u/v)\n      // error for backrefs to undefined captures. So adding captures to the end is a solution that\n      // doesn't change what the regex matches, and lets invalid numbered backrefs through. Note:\n      // Orphan backrefs are only allowed if the `tmGrammar` option is used\n      const numCapsNeeded = Math.max(state.highestOrphanBackref - state.numCapturesToLeft, 0);\n      for (let i = 0; i < numCapsNeeded; i++) {\n        const emptyCapture = createCapturingGroup();\n        node.pattern.alternatives.at(-1).elements.push(emptyCapture);\n      }\n    },\n  },\n};\n\nfunction adoptAndSwapKids(parent, kids) {\n  kids.forEach(kid => kid.parent = parent);\n  parent[getContainerAccessor(parent)] = kids;\n  return parent;\n}\n\nfunction areFlagsEqual(a, b) {\n  return a.dotAll === b.dotAll && a.ignoreCase === b.ignoreCase;\n}\n\nfunction canParticipateWithNode(capture, node, {ancestorsParticipate}) {\n  // Walks to the left (prev siblings), down (sibling descendants), up (parent), then back down\n  // (parent's prev sibling descendants) the tree in a loop\n  let rightmostPoint = node;\n  do {\n    if (rightmostPoint.type === AstTypes.Pattern) {\n      // End of the line; capture is not in node's alternation path\n      return false;\n    }\n    if (rightmostPoint.type === AstTypes.Alternative) {\n      // Skip past alts to their parent because we don't want to look at the kids of preceding alts\n      continue;\n    }\n    if (rightmostPoint === capture) {\n      // Capture is ancestor of node\n      return ancestorsParticipate;\n    }\n    const kidsOfParent = getKids(rightmostPoint.parent);\n    for (const kid of kidsOfParent) {\n      if (kid === rightmostPoint) {\n        // Reached rightmost node in sibling list that we want to consider; break to parent loop\n        break;\n      }\n      if (kid === capture) {\n        return true;\n      }\n      if (hasDescendant(kid, capture)) {\n        return true;\n      }\n    }\n  } while ((rightmostPoint = rightmostPoint.parent));\n  throw new Error('Unexpected path');\n}\n\n// Creates a deep copy of the provided node, with special handling:\n// - Make `parent` props point to their parent in the copy\n// - Update the provided `originMap` for each cloned capturing group (outer and nested)\nfunction cloneCapturingGroup(obj, originMap, up, up2) {\n  const store = Array.isArray(obj) ? [] : {};\n  for (const [key, value] of Object.entries(obj)) {\n    if (key === 'parent') {\n      // If the last cloned item was a container array (for holding kids), use the object above it\n      store.parent = Array.isArray(up) ? up2 : up;\n    } else if (value && typeof value === 'object') {\n      store[key] = cloneCapturingGroup(value, originMap, store, up);\n    } else {\n      if (key === 'type' && value === AstTypes.CapturingGroup) {\n        // Key is the copied node, value is the origin node\n        originMap.set(store, originMap.get(obj) ?? obj);\n      }\n      store[key] = value;\n    }\n  }\n  return store;\n}\n\nfunction createRecursion(ref) {\n  return {\n    type: AstTypes.Recursion,\n    ref,\n  };\n}\n\nfunction getAllParents(node, filterFn) {\n  const results = [];\n  while ((node = node.parent)) {\n    if (!filterFn || filterFn(node)) {\n      results.push(node);\n    }\n  }\n  return results;\n}\n\n// Returns the string key for the container that holds the node's kids\nfunction getContainerAccessor(node) {\n  for (const accessor of ['alternatives', 'classes', 'elements']) {\n    if (node[accessor]) {\n      return accessor;\n    }\n  }\n  return null;\n}\n\nfunction getCombinedFlagModsFromFlagNodes(flagNodes) {\n  const flagProps = ['dotAll', 'ignoreCase'];\n  const combinedFlags = {enable: {}, disable: {}};\n  flagNodes.forEach(({flags}) => {\n    flagProps.forEach(prop => {\n      if (flags.enable?.[prop]) {\n        // Need to remove `disable` since disabled flags take precedence\n        delete combinedFlags.disable[prop];\n        combinedFlags.enable[prop] = true;\n      }\n      if (flags.disable?.[prop]) {\n        combinedFlags.disable[prop] = true;\n      }\n    });\n  });\n  if (!Object.keys(combinedFlags.enable).length) {\n    delete combinedFlags.enable;\n  }\n  if (!Object.keys(combinedFlags.disable).length) {\n    delete combinedFlags.disable;\n  }\n  if (combinedFlags.enable || combinedFlags.disable) {\n    return combinedFlags;\n  }\n  return null;\n}\n\nfunction getFlagModsFromFlags({dotAll, ignoreCase}) {\n  const mods = {};\n  if (dotAll || ignoreCase) {\n    mods.enable = {};\n    dotAll && (mods.enable.dotAll = true);\n    ignoreCase && (mods.enable.ignoreCase = true);\n  }\n  if (!dotAll || !ignoreCase) {\n    mods.disable = {};\n    !dotAll && (mods.disable.dotAll = true);\n    !ignoreCase && (mods.disable.ignoreCase = true);\n  }\n  return mods;\n}\n\nfunction getKids(node) {\n  if (!node) {\n    throw new Error('Node expected');\n  }\n  // [NOTE] Not handling `Regex` kids (`pattern`, `flags`) and `CharacterClassRange` kids (`min`,\n  // `max`) only because not needed by current callers\n  if (node.type === AstTypes.Quantifier) {\n    return [node.element];\n  }\n  const accessor = getContainerAccessor(node);\n  return accessor && node[accessor];\n}\n\nfunction getLeadingG(els) {\n  const firstToConsider = els.find(el => (\n    el.kind === AstAssertionKinds.search_start ||\n    isLoneGLookaround(el, {negate: false}) ||\n    !isZeroLengthNode(el)\n  ));\n  if (!firstToConsider) {\n    return null;\n  }\n  if (firstToConsider.kind === AstAssertionKinds.search_start) {\n    return firstToConsider;\n  }\n  if (isLookaround(firstToConsider)) {\n    return firstToConsider.alternatives[0].elements[0];\n  }\n  if (firstToConsider.type === AstTypes.Group || firstToConsider.type === AstTypes.CapturingGroup) {\n    const gNodesForGroup = [];\n    // Recursively find `\\G` nodes for all alternatives in the group\n    for (const alt of firstToConsider.alternatives) {\n      const leadingG = getLeadingG(alt.elements);\n      if (!leadingG) {\n        // Don't return `gNodesForGroup` collected so far since this alt didn't qualify\n        return null;\n      }\n      Array.isArray(leadingG) ?\n        gNodesForGroup.push(...leadingG) :\n        gNodesForGroup.push(leadingG);\n    }\n    return gNodesForGroup;\n  }\n  return null;\n}\n\nfunction hasDescendant(node, descendant) {\n  const kids = getKids(node) ?? [];\n  for (const kid of kids) {\n    if (\n      kid === descendant ||\n      hasDescendant(kid, descendant)\n    ) {\n      return true;\n    }\n  }\n  return false;\n}\n\nfunction isValidGroupNameJs(name) {\n  // JS group names are more restrictive than Onig; see\n  // <developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Lexical_grammar#identifiers>\n  return /^[$_\\p{IDS}][$\\u200C\\u200D\\p{IDC}]*$/u.test(name);\n}\n\n// Returns a single node, either the given node or all nodes wrapped in a noncapturing group\nfunction parseFragment(pattern, options) {\n  const skipPropertyNameValidation = !!options?.skipPropertyNameValidation;\n  const ast = parse(tokenize(pattern), {skipPropertyNameValidation});\n  const alts = ast.pattern.alternatives;\n  if (alts.length > 1 || alts[0].elements.length > 1) {\n    return adoptAndSwapKids(createGroup(), alts);\n  }\n  return alts[0].elements[0];\n}\n\nfunction prepContainer(node, kids) {\n  const accessor = getContainerAccessor(node);\n  // Set the parent for the default container of a new node\n  node[accessor][0].parent = node;\n  if (kids) {\n    adoptAndSwapKids(node[accessor][0], kids);\n  }\n  return node;\n}\n\nfunction traverseReplacement(replacement, {parent, key, container}, state, visitor) {\n  traverse({\n    // Don't use the `node` from `path`\n    node: replacement,\n    parent,\n    key,\n    container,\n  }, state, visitor);\n}\n\nexport {\n  adoptAndSwapKids,\n  transform,\n};\n", "import {getOptions} from './options.js';\nimport {AstAssertionKinds, AstCharacterSetKinds, AstTypes, isLookaround} from './parse.js';\nimport {traverse} from './traverse.js';\nimport {getIgnoreCaseMatchChars, JsUnicodePropertiesPostEs2018, UnicodePropertiesWithSpecificCase} from './unicode.js';\nimport {cp, getNewCurrentFlags, isMinTarget, r} from './utils.js';\n\n/**\nGenerates a Regex+ compatible `pattern`, `flags`, and `options` from a Regex+ AST.\n@param {import('./transform.js').RegexAst} ast\n@param {import('.').OnigurumaToEsOptions} [options]\n@returns {{\n  pattern: string;\n  flags: string;\n  options: Object;\n}}\n*/\nfunction generate(ast, options) {\n  const opts = getOptions(options);\n  const minTargetEs2024 = isMinTarget(opts.target, 'ES2024');\n  const minTargetEs2025 = isMinTarget(opts.target, 'ES2025');\n  const rDepth = opts.maxRecursionDepth;\n  if (rDepth !== null && (!Number.isInteger(rDepth) || rDepth < 2 || rDepth > 100)) {\n    throw new Error('Invalid maxRecursionDepth; use 2-100 or null');\n  }\n\n  // If the output can't use flag groups, we need a pre-pass to check for the use of chars with\n  // case in case sensitive/insensitive states. This minimizes the need for case expansions (though\n  // expansions are lossless, even given Unicode case complexities) and allows supporting case\n  // insensitive backrefs in more cases\n  // [TODO] Consider gathering this data in the transformer's final traversal to avoid work here\n  let hasCaseInsensitiveNode = null;\n  let hasCaseSensitiveNode = null;\n  if (!minTargetEs2025) {\n    const iStack = [ast.flags.ignoreCase];\n    traverse({node: ast}, {\n      getCurrentModI: () => iStack.at(-1),\n      popModI() {iStack.pop()},\n      pushModI(isIOn) {iStack.push(isIOn)},\n      setHasCasedChar() {\n        if (iStack.at(-1)) {\n          hasCaseInsensitiveNode = true;\n        } else {\n          hasCaseSensitiveNode = true;\n        }\n      },\n    }, FlagModifierVisitor);\n  }\n\n  const appliedGlobalFlags = {\n    dotAll: ast.flags.dotAll,\n    // - Turn global flag i on if a case insensitive node was used and no case sensitive nodes were\n    //   used (to avoid unnecessary node expansion).\n    // - Turn global flag i off if a case sensitive node was used (since case sensitivity can't be\n    //   forced without the use of ES2025 flag groups)\n    ignoreCase: !!((ast.flags.ignoreCase || hasCaseInsensitiveNode) && !hasCaseSensitiveNode),\n  };\n  let lastNode = null;\n  const state = {\n    accuracy: opts.accuracy,\n    appliedGlobalFlags,\n    captureFlagIMap: new Map(),\n    currentFlags: {\n      dotAll: ast.flags.dotAll,\n      ignoreCase: ast.flags.ignoreCase,\n    },\n    groupNames: new Set(),\n    inCharClass: false,\n    lastNode,\n    maxRecursionDepth: rDepth,\n    useAppliedIgnoreCase: !!(!minTargetEs2025 && hasCaseInsensitiveNode && hasCaseSensitiveNode),\n    useDuplicateNames: minTargetEs2025,\n    useFlagMods: minTargetEs2025,\n    useFlagV: minTargetEs2024,\n    usePostEs2018Properties: minTargetEs2024,\n    verbose: opts.verbose,\n  };\n  function gen(node) {\n    state.lastNode = lastNode;\n    lastNode = node;\n    switch (node.type) {\n      case AstTypes.Regex:\n        // Final result is an object; other node types return strings\n        return {\n          pattern: gen(node.pattern),\n          flags: gen(node.flags),\n          options: {...node.options},\n        };\n      case AstTypes.Alternative:\n        return node.elements.map(gen).join('');\n      case AstTypes.Assertion:\n        return genAssertion(node, state, gen);\n      case AstTypes.Backreference:\n        return genBackreference(node, state);\n      case AstTypes.CapturingGroup:\n        return genCapturingGroup(node, state, gen);\n      case AstTypes.Character:\n        return genCharacter(node, state);\n      case AstTypes.CharacterClass:\n        return genCharacterClass(node, state, gen);\n      case AstTypes.CharacterClassIntersection:\n        if (!state.useFlagV) {\n          throw new Error('Use of class intersection requires min target ES2024');\n        }\n        return node.classes.map(gen).join('&&');\n      case AstTypes.CharacterClassRange:\n        return genCharacterClassRange(node, state);\n      case AstTypes.CharacterSet:\n        return genCharacterSet(node, state);\n      case AstTypes.Flags:\n        return genFlags(node, state);\n      case AstTypes.Group:\n        return genGroup(node, state, gen);\n      case AstTypes.Pattern:\n        return node.alternatives.map(gen).join('|');\n      case AstTypes.Quantifier:\n        return gen(node.element) + getQuantifierStr(node);\n      case AstTypes.Recursion:\n        return genRecursion(node, state);\n      default:\n        // Node types `Directive`, `Subroutine`, and `VariableLengthCharacterSet` are never\n        // included in transformer output\n        throw new Error(`Unexpected node type \"${node.type}\"`);\n    }\n  }\n\n  const result = gen(ast);\n  if (!minTargetEs2024) {\n    // Switch from flag v to u. By default, Regex+ implicitly chooses; control it instead\n    delete result.options.force.v;\n    result.options.disable.v = true;\n    result.options.unicodeSetsPlugin = null;\n  }\n  return result;\n}\n\nconst FlagModifierVisitor = {\n  AnyGroup: {\n    enter({node}, state) {\n      const currentModI = state.getCurrentModI();\n      state.pushModI(\n        node.flags ?\n          getNewCurrentFlags({ignoreCase: currentModI}, node.flags).ignoreCase :\n          currentModI\n      );\n    },\n    exit(_, state) {\n      state.popModI();\n    },\n  },\n  Backreference(_, state) {\n    // Can't know for sure, so assume the backref will include chars with case (best that could be\n    // done is not calling `setHasCasedChar` if the reffed group doesn't contain a char with case\n    // or most kinds of char sets)\n    state.setHasCasedChar();\n  },\n  Character({node}, state) {\n    if (charHasCase(cp(node.value))) {\n      state.setHasCasedChar();\n    }\n  },\n  CharacterClassRange({node, skip}, state) {\n    skip();\n    if (getCasesOutsideCharClassRange(node, {firstOnly: true}).length) {\n      state.setHasCasedChar();\n    }\n  },\n  CharacterSet({node}, state) {\n    if (\n      node.kind === AstCharacterSetKinds.property &&\n      UnicodePropertiesWithSpecificCase.has(node.value)\n    ) {\n      state.setHasCasedChar();\n    }\n  },\n};\n\nconst BaseEscapeChars = new Set([\n  '$', '(', ')', '*', '+', '.', '?', '[', '\\\\', ']', '^', '{', '|', '}',\n]);\nconst CharClassEscapeChars = new Set([\n  '-', '\\\\', ']', '^',\n]);\nconst CharClassEscapeCharsFlagV = new Set([\n  '(', ')', '-', '/', '[', '\\\\', ']', '^', '{', '|', '}',\n  // Double punctuators; also includes already-listed `-` and `^`\n  '!', '#', '$', '%', '&', '*', '+', ',', '.', ':', ';', '<', '=', '>', '?', '@', '`', '~',\n]);\nconst CharCodeEscapeMap = new Map([\n  [ 9, r`\\t`], // horizontal tab\n  [10, r`\\n`], // line feed\n  [11, r`\\v`], // vertical tab\n  [12, r`\\f`], // form feed\n  [13, r`\\r`], // carriage return\n  [0x2028, r`\\u2028`], // line separator\n  [0x2029, r`\\u2029`], // paragraph separator\n  [0xFEFF, r`\\uFEFF`], // ZWNBSP/BOM\n]);\n\nconst casedRe = /^\\p{Cased}$/u;\nfunction charHasCase(char) {\n  return casedRe.test(char);\n}\n\nfunction genAssertion(node, _, gen) {\n  const {kind, negate, alternatives} = node;\n  if (isLookaround(node)) {\n    const prefix = `${kind === AstAssertionKinds.lookahead ? '' : '<'}${negate ? '!' : '='}`;\n    return `(?${prefix}${alternatives.map(gen).join('|')})`;\n  }\n  // Can always use `^` and `$` for string boundaries since JS flag m is never relied on; Onig uses\n  // different line break chars\n  if (kind === AstAssertionKinds.string_end) {\n    return '$';\n  }\n  if (kind === AstAssertionKinds.string_start) {\n    return '^';\n  }\n  // Kinds `line_end`, `line_start`, `search_start`, `string_end_newline`, and `word_boundary` are\n  // never included in transformer output\n  throw new Error(`Unexpected assertion kind \"${kind}\"`);\n}\n\nfunction genBackreference({ref}, state) {\n  if (typeof ref !== 'number') {\n    throw new Error('Unexpected named backref in transformed AST');\n  }\n  if (\n    !state.useFlagMods &&\n    state.accuracy === 'strict' &&\n    state.currentFlags.ignoreCase &&\n    !state.captureFlagIMap.get(ref)\n  ) {\n    throw new Error('Use of case-insensitive backref to case-sensitive group requires target ES2025 or non-strict accuracy');\n  }\n  return '\\\\' + ref;\n}\n\nfunction genCapturingGroup({name, number, alternatives}, state, gen) {\n  if (name) {\n    if (state.groupNames.has(name)) {\n      if (!state.useDuplicateNames) {\n        // Keep the name only in the first alternation path that used it; the transformer already\n        // stripped all but the last duplicate name per alternation path\n        name = null;\n      }\n    } else {\n      state.groupNames.add(name);\n    }\n  }\n  state.captureFlagIMap.set(number, state.currentFlags.ignoreCase);\n  return `(${name ? `?<${name}>` : ''}${alternatives.map(gen).join('|')})`;\n}\n\nfunction genCharacter({value}, state) {\n  const char = cp(value);\n  const escaped = getCharEscape(value, {\n    isAfterBackref: state.lastNode.type === AstTypes.Backreference,\n    inCharClass: state.inCharClass,\n    useFlagV: state.useFlagV,\n  });\n  if (escaped !== char) {\n    return escaped;\n  }\n  if (state.useAppliedIgnoreCase && state.currentFlags.ignoreCase && charHasCase(char)) {\n    const cases = getIgnoreCaseMatchChars(char);\n    return state.inCharClass ?\n      cases.join('') :\n      (cases.length > 1 ? `[${cases.join('')}]` : cases[0]);\n  }\n  return char;\n}\n\nfunction genCharacterClass({negate, parent, elements}, state, gen) {\n  if (\n    !negate &&\n    ( // Allows many nested classes to work with `target` ES2018 which doesn't support nesting\n      (!state.useFlagV || !state.verbose) &&\n      parent.type === AstTypes.CharacterClass &&\n      elements[0].type !== AstTypes.CharacterClassIntersection\n    ) ||\n    ( !state.verbose &&\n      parent.type === AstTypes.CharacterClassIntersection &&\n      elements.length === 1 &&\n      elements[0].type !== AstTypes.CharacterClassRange\n    )\n  ) {\n    // Remove unnecessary nesting; unwrap kids into the parent char class. Some basic char class\n    // optimization has already been done in the parser\n    return elements.map(gen).join('');\n  }\n  if (!state.useFlagV && parent.type === AstTypes.CharacterClass) {\n    throw new Error('Use of nested character class requires min target ES2024');\n  }\n  state.inCharClass = true;\n  const result = `[${negate ? '^' : ''}${elements.map(gen).join('')}]`;\n  state.inCharClass = false;\n  return result;\n}\n\nfunction genCharacterClassRange(node, state) {\n  const min = node.min.value;\n  const max = node.max.value;\n  const escOpts = {\n    isAfterBackref: false,\n    inCharClass: true,\n    useFlagV: state.useFlagV,\n  };\n  const minStr = getCharEscape(min, escOpts);\n  const maxStr = getCharEscape(max, escOpts);\n  let extraChars = '';\n  if (state.useAppliedIgnoreCase && state.currentFlags.ignoreCase) {\n    // [TODO] Avoid duplication by considering other chars in the parent char class when expanding\n    const charsOutsideRange = getCasesOutsideCharClassRange(node);\n    const ranges = getCodePointRangesFromChars(charsOutsideRange);\n    ranges.forEach(value => {\n      extraChars += Array.isArray(value) ?\n        `${getCharEscape(value[0], escOpts)}-${getCharEscape(value[1], escOpts)}` :\n        getCharEscape(value, escOpts);\n    });\n  }\n  // Create the range without calling `gen` on the `min`/`max` kids\n  return `${minStr}-${maxStr}${extraChars}`;\n}\n\nfunction genCharacterSet({kind, negate, value, key}, state) {\n  if (kind === AstCharacterSetKinds.dot) {\n    return state.currentFlags.dotAll ?\n      ((state.appliedGlobalFlags.dotAll || state.useFlagMods) ? '.' : '[^]') :\n      // Onig's only line break char is line feed, unlike JS\n      r`[^\\n]`;\n  }\n  if (kind === AstCharacterSetKinds.digit) {\n    return negate ? r`\\D` : r`\\d`;\n  }\n  if (kind === AstCharacterSetKinds.property) {\n    if (!state.usePostEs2018Properties && JsUnicodePropertiesPostEs2018.has(value)) {\n      throw new Error(`Unicode property \"${value}\" unavailable in target ES2018`);\n    }\n    if (\n      state.useAppliedIgnoreCase &&\n      state.currentFlags.ignoreCase &&\n      UnicodePropertiesWithSpecificCase.has(value)\n    ) {\n      // Support for this would require heavy Unicode data. Could change e.g. `\\p{Lu}` to `\\p{LC}`\n      // if not using strict `accuracy` (since it's close but not 100%), but this wouldn't work\n      // for e.g. `\\p{Lt}`, and in any case, it's probably user error if using these case-specific\n      // props case-insensitively\n      throw new Error(`Unicode property \"${value}\" can't be case-insensitive when other chars have specific case`);\n    }\n    return `${negate ? r`\\P` : r`\\p`}{${key ? `${key}=` : ''}${value}}`;\n  }\n  if (kind === AstCharacterSetKinds.word) {\n    return negate ? r`\\W` : r`\\w`;\n  }\n  // Kinds `hex`, `posix`, and `space` are never included in transformer output\n  throw new Error(`Unexpected character set kind \"${kind}\"`);\n}\n\nfunction genFlags(node, state) {\n  return (\n    // The transformer should never turn on the properties for flags d, g, and m since Onig doesn't\n    // have equivs. Flag m is never relied on since Onig uses different line break chars than JS\n    // (node.hasIndices ? 'd' : '') +\n    // (node.global ? 'g' : '') +\n    // (node.multiline ? 'm' : '') +\n    (state.appliedGlobalFlags.ignoreCase ? 'i' : '') +\n    (node.dotAll ? 's' : '') +\n    (node.sticky ? 'y' : '')\n    // Regex+ doesn't allow explicitly adding flags it handles implicitly, so there are no\n    // `unicode` (flag u) or `unicodeSets` (flag v) props; those flags are added separately\n  );\n}\n\nfunction genGroup({atomic, flags, parent, alternatives}, state, gen) {\n  const currentFlags = state.currentFlags;\n  if (flags) {\n    state.currentFlags = getNewCurrentFlags(currentFlags, flags);\n  }\n  const contents = alternatives.map(gen).join('|');\n  const result = (\n    !state.verbose &&\n    alternatives.length === 1 &&\n    parent.type !== AstTypes.Quantifier &&\n    !atomic &&\n    (!state.useFlagMods || !flags)\n   ) ? contents : `(?${getGroupPrefix(atomic, flags, state.useFlagMods)}${contents})`;\n  state.currentFlags = currentFlags;\n  return result;\n}\n\nfunction genRecursion({ref}, state) {\n  const rDepth = state.maxRecursionDepth;\n  if (!rDepth) {\n    throw new Error('Use of recursion disabled');\n  }\n  if (state.accuracy === 'strict') {\n    throw new Error('Use of recursion requires non-strict accuracy due to depth limit');\n  }\n  // Using the syntax supported by `regex-recursion`\n  return ref === 0 ? `(?R=${rDepth})` : r`\\g<${ref}&R=${rDepth}>`;\n}\n\n/**\nGiven a `CharacterClassRange` node, returns an array of chars that are a case variant of a char in\nthe range, and aren't already in the range.\n*/\nfunction getCasesOutsideCharClassRange(node, options) {\n  const firstOnly = !!options?.firstOnly;\n  const min = node.min.value;\n  const max = node.max.value;\n  const found = [];\n  // Avoid unneeded work. Assumptions (per Unicode 16):\n  // - No case variants cross the Basic Multilingual Plane boundary\n  // - No cased chars appear beyond the Supplementary Multilingual Plane\n  if ((min < 65 && (max === 0xFFFF || max >= 0x1FFFF)) || (min === 0x10000 && max >= 0x1FFFF)) {\n    return found;\n  }\n  for (let i = min; i <= max; i++) {\n    const char = cp(i);\n    if (!charHasCase(char)) {\n      continue;\n    }\n    const charsOutsideRange = getIgnoreCaseMatchChars(char).filter(caseOfChar => {\n      const num = caseOfChar.codePointAt(0);\n      return num < min || num > max;\n    });\n    if (charsOutsideRange.length) {\n      found.push(...charsOutsideRange);\n      if (firstOnly) {\n        break;\n      }\n    }\n  }\n  return found;\n}\n\n// This shouldn't modifiy any char that has case\nfunction getCharEscape(codePoint, {isAfterBackref, inCharClass, useFlagV}) {\n  if (CharCodeEscapeMap.has(codePoint)) {\n    return CharCodeEscapeMap.get(codePoint);\n  }\n  if (\n    // Control chars, etc.; condition modeled on the Chrome developer console's display for strings\n    codePoint < 32 || (codePoint > 126 && codePoint < 160) ||\n    // Unicode planes 4-16; unassigned, special purpose, and private use area\n    codePoint > 0x3FFFF ||\n    // Avoid corrupting a preceding backref by immediately following it with a literal digit\n    (isAfterBackref && isDigitCharCode(codePoint))\n  ) {\n    // Don't convert codePoint `0` to `\\0` since that's corruptible by following literal digits\n    return codePoint > 0xFF ?\n      `\\\\u{${codePoint.toString(16).toUpperCase()}}` :\n      `\\\\x${codePoint.toString(16).toUpperCase().padStart(2, '0')}`;\n  }\n  const escapeChars = inCharClass ?\n    (useFlagV ? CharClassEscapeCharsFlagV : CharClassEscapeChars) :\n    BaseEscapeChars;\n  const char = cp(codePoint);\n  return (escapeChars.has(char) ? '\\\\' : '') + char;\n}\n\nfunction getCodePointRangesFromChars(chars) {\n  const codePoints = chars.map(char => char.codePointAt(0)).sort((a, b) => a - b);\n  const values = [];\n  let start = null;\n  for (let i = 0; i < codePoints.length; i++) {\n    if (codePoints[i + 1] === codePoints[i] + 1) {\n      start ??= codePoints[i];\n    } else if (start === null) {\n      values.push(codePoints[i]);\n    } else {\n      values.push([start, codePoints[i]]);\n      start = null;\n    }\n  }\n  return values;\n}\n\nfunction getGroupPrefix(atomic, flagMods, useFlagMods) {\n  if (atomic) {\n    return '>';\n  }\n  let mods = '';\n  if (flagMods && useFlagMods) {\n    const {enable, disable} = flagMods;\n    mods =\n      (enable?.ignoreCase ? 'i' : '') +\n      (enable?.dotAll ? 's' : '') +\n      (disable ? '-' : '') +\n      (disable?.ignoreCase ? 'i' : '') +\n      (disable?.dotAll ? 's' : '');\n  }\n  return `${mods}:`;\n}\n\nfunction getQuantifierStr({min, max, greedy, possessive}) {\n  let base;\n  if (!min && max === 1) {\n    base = '?';\n  } else if (!min && max === Infinity) {\n    base = '*';\n  } else if (min === 1 && max === Infinity) {\n    base = '+';\n  } else if (min === max) {\n    base = `{${min}}`;\n  } else {\n    base = `{${min},${max === Infinity ? '' : max}}`;\n  }\n  return base + (possessive ? '+' : (greedy ? '' : '?'));\n}\n\nfunction isDigitCharCode(value) {\n  return value > 47 && value < 58;\n}\n\nexport {\n  generate,\n};\n", "// Constant properties for tracking regex syntax context\nexport const Context = Object.freeze({\n  DEFAULT: 'DEFAULT',\n  CHAR_CLASS: 'CHAR_CLASS',\n});\n\n/**\nReplaces all unescaped instances of a regex pattern in the given context, using a replacement\nstring or callback.\n\nDoesn't skip over complete multicharacter tokens (only `\\` plus its folowing char) so must be used\nwith knowledge of what's safe to do given regex syntax. Assumes UnicodeSets-mode syntax.\n@param {string} expression Search target\n@param {string} needle Search as a regex pattern, with flags `su` applied\n@param {string | (match: RegExpExecArray, details: {\n  context: 'DEFAULT' | 'CHAR_CLASS';\n  negated: boolean;\n}) => string} replacement\n@param {'DEFAULT' | 'CHAR_CLASS'} [context] All contexts if not specified\n@returns {string} Updated expression\n@example\nconst str = '.\\\\.\\\\\\\\.[[\\\\.].].';\nreplaceUnescaped(str, '\\\\.', '@');\n// \u2192 '@\\\\.\\\\\\\\@[[\\\\.]@]@'\nreplaceUnescaped(str, '\\\\.', '@', Context.DEFAULT);\n// \u2192 '@\\\\.\\\\\\\\@[[\\\\.].]@'\nreplaceUnescaped(str, '\\\\.', '@', Context.CHAR_CLASS);\n// \u2192 '.\\\\.\\\\\\\\.[[\\\\.]@].'\n*/\nexport function replaceUnescaped(expression, needle, replacement, context) {\n  const re = new RegExp(String.raw`${needle}|(?<$skip>\\[\\^?|\\\\?.)`, 'gsu');\n  const negated = [false];\n  let numCharClassesOpen = 0;\n  let result = '';\n  for (const match of expression.matchAll(re)) {\n    const {0: m, groups: {$skip}} = match;\n    if (!$skip && (!context || (context === Context.DEFAULT) === !numCharClassesOpen)) {\n      if (replacement instanceof Function) {\n        result += replacement(match, {\n          context: numCharClassesOpen ? Context.CHAR_CLASS : Context.DEFAULT,\n          negated: negated[negated.length - 1],\n        });\n      } else {\n        result += replacement;\n      }\n      continue;\n    }\n    if (m[0] === '[') {\n      numCharClassesOpen++;\n      negated.push(m[1] === '^');\n    } else if (m === ']' && numCharClassesOpen) {\n      numCharClassesOpen--;\n      negated.pop();\n    }\n    result += m;\n  }\n  return result;\n}\n\n/**\nRuns a callback for each unescaped instance of a regex pattern in the given context.\n\nDoesn't skip over complete multicharacter tokens (only `\\` plus its folowing char) so must be used\nwith knowledge of what's safe to do given regex syntax. Assumes UnicodeSets-mode syntax.\n@param {string} expression Search target\n@param {string} needle Search as a regex pattern, with flags `su` applied\n@param {(match: RegExpExecArray, details: {\n  context: 'DEFAULT' | 'CHAR_CLASS';\n  negated: boolean;\n}) => void} callback\n@param {'DEFAULT' | 'CHAR_CLASS'} [context] All contexts if not specified\n*/\nexport function forEachUnescaped(expression, needle, callback, context) {\n  // Do this the easy way\n  replaceUnescaped(expression, needle, callback, context);\n}\n\n/**\nReturns a match object for the first unescaped instance of a regex pattern in the given context, or\n`null`.\n\nDoesn't skip over complete multicharacter tokens (only `\\` plus its folowing char) so must be used\nwith knowledge of what's safe to do given regex syntax. Assumes UnicodeSets-mode syntax.\n@param {string} expression Search target\n@param {string} needle Search as a regex pattern, with flags `su` applied\n@param {number} [pos] Offset to start the search\n@param {'DEFAULT' | 'CHAR_CLASS'} [context] All contexts if not specified\n@returns {RegExpExecArray | null}\n*/\nexport function execUnescaped(expression, needle, pos = 0, context) {\n  // Quick partial test; avoid the loop if not needed\n  if (!(new RegExp(needle, 'su').test(expression))) {\n    return null;\n  }\n  const re = new RegExp(`${needle}|(?<$skip>\\\\\\\\?.)`, 'gsu');\n  re.lastIndex = pos;\n  let numCharClassesOpen = 0;\n  let match;\n  while (match = re.exec(expression)) {\n    const {0: m, groups: {$skip}} = match;\n    if (!$skip && (!context || (context === Context.DEFAULT) === !numCharClassesOpen)) {\n      return match;\n    }\n    if (m === '[') {\n      numCharClassesOpen++;\n    } else if (m === ']' && numCharClassesOpen) {\n      numCharClassesOpen--;\n    }\n    // Avoid an infinite loop on zero-length matches\n    if (re.lastIndex == match.index) {\n      re.lastIndex++;\n    }\n  }\n  return null;\n}\n\n/**\nChecks whether an unescaped instance of a regex pattern appears in the given context.\n\nDoesn't skip over complete multicharacter tokens (only `\\` plus its folowing char) so must be used\nwith knowledge of what's safe to do given regex syntax. Assumes UnicodeSets-mode syntax.\n@param {string} expression Search target\n@param {string} needle Search as a regex pattern, with flags `su` applied\n@param {'DEFAULT' | 'CHAR_CLASS'} [context] All contexts if not specified\n@returns {boolean} Whether the pattern was found\n*/\nexport function hasUnescaped(expression, needle, context) {\n  // Do this the easy way\n  return !!execUnescaped(expression, needle, 0, context);\n}\n\n/**\nExtracts the full contents of a group (subpattern) from the given expression, accounting for\nescaped characters, nested groups, and character classes. The group is identified by the position\nwhere its contents start (the string index just after the group's opening delimiter). Returns the\nrest of the string if the group is unclosed.\n\nAssumes UnicodeSets-mode syntax.\n@param {string} expression Search target\n@param {number} contentsStartPos\n@returns {string}\n*/\nexport function getGroupContents(expression, contentsStartPos) {\n  const token = /\\\\?./gsu;\n  token.lastIndex = contentsStartPos;\n  let contentsEndPos = expression.length;\n  let numCharClassesOpen = 0;\n  // Starting search within an open group, after the group's opening\n  let numGroupsOpen = 1;\n  let match;\n  while (match = token.exec(expression)) {\n    const [m] = match;\n    if (m === '[') {\n      numCharClassesOpen++;\n    } else if (!numCharClassesOpen) {\n      if (m === '(') {\n        numGroupsOpen++;\n      } else if (m === ')') {\n        numGroupsOpen--;\n        if (!numGroupsOpen) {\n          contentsEndPos = match.index;\n          break;\n        }\n      }\n    } else if (m === ']') {\n      numCharClassesOpen--;\n    }\n  }\n  return expression.slice(contentsStartPos, contentsEndPos);\n}\n", "import {Context, replaceUnescaped} from 'regex-utilities';\n\n// This marker was chosen because it's impossible to match (so its extemely unlikely to be used in\n// a user-provided regex); it's not at risk of being optimized away, transformed, or flagged as an\n// error by a plugin; and it ends with an unquantifiable token\nconst emulationGroupMarker = '$E$';\n\n/**\n@class\n@param {string | RegExpSubclass} expression\n@param {string} [flags]\n@param {{useEmulationGroups: boolean;}} [options]\n*/\nclass RegExpSubclass extends RegExp {\n  // Avoid #private to allow for subclassing\n  _captureMap;\n  constructor(expression, flags, options) {\n    let captureMap;\n    if (options?.useEmulationGroups) {\n      ({expression, captureMap} = unmarkEmulationGroups(expression));\n    }\n    super(expression, flags);\n    if (captureMap) {\n      this._captureMap = captureMap;\n    // The third argument `options` isn't provided when regexes are copied as part of the internal\n    // handling of string methods `matchAll` and `split`\n    } else if (expression instanceof RegExpSubclass) {\n      this._captureMap = expression._captureMap;\n    }\n  }\n  /**\n  Called internally by all String/RegExp methods that use regexes.\n  @override\n  @param {string} str\n  @returns {RegExpExecArray | null}\n  */\n  exec(str) {\n    const match = RegExp.prototype.exec.call(this, str);\n    if (!match || !this._captureMap) {\n      return match;\n    }\n    const matchCopy = [...match];\n    // Empty all but the first value of the array while preserving its other properties\n    match.length = 1;\n    let indicesCopy;\n    if (this.hasIndices) {\n      indicesCopy = [...match.indices];\n      match.indices.length = 1;\n    }\n    for (let i = 1; i < matchCopy.length; i++) {\n      if (this._captureMap[i]) {\n        match.push(matchCopy[i]);\n        if (this.hasIndices) {\n          match.indices.push(indicesCopy[i]);\n        }\n      }\n    }\n    return match;\n  }\n}\n\n/**\nBuild the capturing group map (with emulation groups marked as `false` to indicate their submatches\nshouldn't appear in results), and remove the markers for anonymous captures which were added to\nemulate extended syntax.\n@param {string} expression\n@returns {{expression: string; captureMap: Array<boolean>;}}\n*/\nfunction unmarkEmulationGroups(expression) {\n  const marker = emulationGroupMarker.replace(/\\$/g, '\\\\$');\n  const captureMap = [true];\n  expression = replaceUnescaped(\n    expression,\n    String.raw`\\((?:(?!\\?)|\\?<(?![=!])[^>]+>)(?<mark>${marker})?`,\n    ({0: m, groups: {mark}}) => {\n      if (mark) {\n        captureMap.push(false);\n        return m.slice(0, -emulationGroupMarker.length);\n      }\n      captureMap.push(true);\n      return m;\n    },\n    Context.DEFAULT\n  );\n  return {\n    captureMap,\n    expression,\n  };\n}\n\nexport {\n  emulationGroupMarker,\n  RegExpSubclass,\n};\n", "import {Pattern, pattern} from './pattern.js';\nimport {Context, forEachUnescaped, replaceUnescaped} from 'regex-utilities';\n\nexport const RegexContext = {\n  DEFAULT: 'DEFAULT',\n  CHAR_CLASS: 'CHAR_CLASS',\n  ENCLOSED_P: 'ENCLOSED_P',\n  ENCLOSED_U: 'ENCLOSED_U',\n  GROUP_NAME: 'GROUP_NAME',\n  INTERVAL_QUANTIFIER: 'INTERVAL_QUANTIFIER',\n  INVALID_INCOMPLETE_TOKEN: 'INVALID_INCOMPLETE_TOKEN',\n};\n\nexport const CharClassContext = {\n  DEFAULT: 'DEFAULT',\n  ENCLOSED_P: 'ENCLOSED_P',\n  ENCLOSED_Q: 'ENCLOSED_Q',\n  ENCLOSED_U: 'ENCLOSED_U',\n  INVALID_INCOMPLETE_TOKEN: 'INVALID_INCOMPLETE_TOKEN',\n  RANGE: 'RANGE',\n};\n\nexport const enclosedTokenRegexContexts = new Set([\n  RegexContext.ENCLOSED_P,\n  RegexContext.ENCLOSED_U,\n]);\n\nexport const enclosedTokenCharClassContexts = new Set([\n  CharClassContext.ENCLOSED_P,\n  CharClassContext.ENCLOSED_Q,\n  CharClassContext.ENCLOSED_U,\n]);\n\nexport const patternModsSupported = (() => {\n  try {\n    new RegExp('(?i:)');\n  } catch (e) {\n    return false;\n  }\n  return true;\n})();\n\nexport const flagVSupported = (() => {\n  try {\n    new RegExp('', 'v');\n  } catch (e) {\n    return false;\n  }\n  return true;\n})();\n\nexport const doublePunctuatorChars = '&!#$%*+,.:;<=>?@^`~';\nexport const namedCapturingDelim = String.raw`\\(\\?<(?![=!])(?<captureName>[^>]+)>`;\nexport const capturingDelim = String.raw`\\((?!\\?)(?!(?<=\\(\\?\\()DEFINE\\))|${namedCapturingDelim}`;\nexport const noncapturingDelim = String.raw`\\(\\?(?:[:=!>A-Za-z\\-]|<[=!]|\\(DEFINE\\))`;\n\n/**\n@param {string} expression\n@param {number} precedingCaptures\n@returns {string}\n*/\nexport function adjustNumberedBackrefs(expression, precedingCaptures) {\n  return replaceUnescaped(\n    expression,\n    String.raw`\\\\(?<num>[1-9]\\d*)`,\n    ({groups: {num}}) => `\\\\${+num + precedingCaptures}`,\n    Context.DEFAULT\n  );\n}\n\n// Properties of strings as of ES2024\nconst stringPropertyNames = [\n  'Basic_Emoji',\n  'Emoji_Keycap_Sequence',\n  'RGI_Emoji_Modifier_Sequence',\n  'RGI_Emoji_Flag_Sequence',\n  'RGI_Emoji_Tag_Sequence',\n  'RGI_Emoji_ZWJ_Sequence',\n  'RGI_Emoji',\n].join('|');\nconst charClassUnionToken = new RegExp(String.raw`\n\\\\(?: c[A-Za-z]\n  | p\\{(?<pStrProp>${stringPropertyNames})\\}\n  | [pP]\\{[^\\}]+\\}\n  | (?<qStrProp>q)\n  | u(?:[A-Fa-f\\d]{4}|\\{[A-Fa-f\\d]+\\})\n  | x[A-Fa-f\\d]{2}\n  | .\n)\n| --\n| &&\n| .\n`.replace(/\\s+/g, ''), 'gsu');\n\n// Assumes flag v and doesn't worry about syntax errors that are caught by it\nexport function containsCharClassUnion(charClassPattern) {\n  // Return `true` if it contains:\n  // - `\\p` (lowercase only) and the name is a property of strings (case sensitive).\n  // - `\\q`.\n  // - Two single-char-matching tokens in sequence.\n  // - One single-char-matching token followed immediately by unescaped `[`.\n  // - One single-char-matching token preceded immediately by unescaped `]`.\n  // Else, `false`.\n  // Ranges with `-` create a single token.\n  // Subtraction and intersection with `--` and `&&` create a single token.\n  // Supports any number of nested classes\n  let hasFirst = false;\n  let lastM;\n  for (const {0: m, groups} of charClassPattern.matchAll(charClassUnionToken)) {\n    if (groups.pStrProp || groups.qStrProp) {\n      return true;\n    }\n    if (m === '[' && hasFirst) {\n      return true;\n    }\n    if (['-', '--', '&&'].includes(m)) {\n      hasFirst = false;\n    } else if (m !== '[' && m !== ']') {\n      if (hasFirst || lastM === ']') {\n        return true;\n      }\n      hasFirst = true;\n    }\n    lastM = m;\n  }\n  return false;\n}\n\n/**\n@param {string} expression\n@returns {number}\n*/\nexport function countCaptures(expression) {\n  let num = 0;\n  forEachUnescaped(expression, capturingDelim, () => num++, Context.DEFAULT);\n  return num;\n}\n\n/**\nEscape special characters for the given context, assuming flag v.\n@param {string} str String to escape\n@param {'DEFAULT' | 'CHAR_CLASS'} context `Context` option from lib `regex-utilities`\n@returns {string} Escaped string\n*/\nexport function escapeV(str, context) {\n  if (context === Context.CHAR_CLASS) {\n    // Escape all double punctuators (including ^, which is special on its own in the first\n    // position) in case they're bordered by the same character in or outside of the escaped string\n    return str.replace(new RegExp(String.raw`[()\\[\\]{}|\\\\/\\-${doublePunctuatorChars}]`, 'g'), '\\\\$&');\n  }\n  return str.replace(/[()\\[\\]{}|\\\\^$*+?.]/g, '\\\\$&');\n}\n\n// Look for characters that would change the meaning of subsequent tokens outside an interpolated value\nexport function getBreakoutChar(expression, regexContext, charClassContext) {\n  const escapesRemoved = expression.replace(/\\\\./gsu, '');\n  // Trailing unescaped `\\`; checking `.includes('\\\\')` would also work\n  if (escapesRemoved.endsWith('\\\\')) {\n    return '\\\\';\n  }\n  if (regexContext === RegexContext.DEFAULT) {\n    // Unbalanced `[` or `]` are also errors but don't breakout; they're caught by the wrapper\n    return getUnbalancedChar(escapesRemoved, '(', ')');\n  } else if (\n    regexContext === RegexContext.CHAR_CLASS &&\n    !enclosedTokenCharClassContexts.has(charClassContext)\n  ) {\n    return getUnbalancedChar(escapesRemoved, '[', ']');\n  } else if (\n    regexContext === RegexContext.INTERVAL_QUANTIFIER ||\n    enclosedTokenRegexContexts.has(regexContext) ||\n    enclosedTokenCharClassContexts.has(charClassContext)\n  ) {\n    if (escapesRemoved.includes('}')) {\n      return '}';\n    }\n  } else if (regexContext === RegexContext.GROUP_NAME) {\n    if (escapesRemoved.includes('>')) {\n      return '>';\n    }\n  }\n  return '';\n}\n\nconst contextToken = new RegExp(String.raw`\n(?<groupN>\\(\\?<(?![=!])|\\\\[gk]<)\n| (?<enclosedPU>\\\\[pPu]\\{)\n| (?<enclosedQ>\\\\q\\{)\n| (?<intervalQ>\\{)\n| (?<incompleteT>\\\\(?: $\n  | c(?![A-Za-z])\n  | u(?![A-Fa-f\\d]{4})[A-Fa-f\\d]{0,3}\n  | x(?![A-Fa-f\\d]{2})[A-Fa-f\\d]?\n  )\n)\n| --\n| \\\\?.\n`.replace(/\\s+/g, ''), 'gsu');\n\n/**\n@typedef {{\n  regexContext: string;\n  charClassContext: string;\n  charClassDepth: number;\n  lastPos: number;\n}} RunningContext\n*/\n/**\nAccepts and returns its full state so it doesn't have to reprocess parts that have already been\nseen. Assumes flag v and doesn't worry about syntax errors that are caught by it.\n@param {string} incompleteExpression\n@param {Partial<RunningContext>} [runningContext]\n@returns {RunningContext}\n*/\nexport function getEndContextForIncompleteExpression(incompleteExpression, {\n  regexContext = RegexContext.DEFAULT,\n  charClassContext = CharClassContext.DEFAULT,\n  charClassDepth = 0,\n  lastPos = 0,\n} = {}) {\n  contextToken.lastIndex = lastPos;\n  let match;\n  while (match = contextToken.exec(incompleteExpression)) {\n    const {0: m, groups: {groupN, enclosedPU, enclosedQ, intervalQ, incompleteT}} = match;\n    if (m === '[') {\n      charClassDepth++;\n      regexContext = RegexContext.CHAR_CLASS;\n      charClassContext = CharClassContext.DEFAULT;\n    } else if (m === ']' && regexContext === RegexContext.CHAR_CLASS) {\n      if (charClassDepth) {\n        charClassDepth--;\n      }\n      if (!charClassDepth) {\n        regexContext = RegexContext.DEFAULT;\n      }\n      charClassContext = CharClassContext.DEFAULT;\n    } else if (regexContext === RegexContext.CHAR_CLASS) {\n      if (incompleteT) {\n        charClassContext = CharClassContext.INVALID_INCOMPLETE_TOKEN;\n      } else if (m === '-') {\n        charClassContext = CharClassContext.RANGE;\n      } else if (enclosedPU) {\n        charClassContext = m[1] === 'u' ? CharClassContext.ENCLOSED_U : CharClassContext.ENCLOSED_P;\n      } else if (enclosedQ) {\n        charClassContext = CharClassContext.ENCLOSED_Q;\n      } else if (\n        (m === '}' && enclosedTokenCharClassContexts.has(charClassContext)) ||\n        // Don't continue in these contexts since we've advanced another token\n        charClassContext === CharClassContext.INVALID_INCOMPLETE_TOKEN ||\n        charClassContext === CharClassContext.RANGE\n      ) {\n        charClassContext = CharClassContext.DEFAULT;\n      }\n    } else {\n      if (incompleteT) {\n        regexContext = RegexContext.INVALID_INCOMPLETE_TOKEN;\n      } else if (groupN) {\n        regexContext = RegexContext.GROUP_NAME;\n      } else if (enclosedPU) {\n        regexContext = m[1] === 'u' ? RegexContext.ENCLOSED_U : RegexContext.ENCLOSED_P;\n      } else if (intervalQ) {\n        regexContext = RegexContext.INTERVAL_QUANTIFIER;\n      } else if (\n        (m === '>' && regexContext === RegexContext.GROUP_NAME) ||\n        (m === '}' && (regexContext === RegexContext.INTERVAL_QUANTIFIER || enclosedTokenRegexContexts.has(regexContext))) ||\n        // Don't continue in this context since we've advanced another token\n        regexContext === RegexContext.INVALID_INCOMPLETE_TOKEN\n       ) {\n        regexContext = RegexContext.DEFAULT;\n      }\n    }\n  }\n  return {\n    regexContext,\n    charClassContext,\n    charClassDepth,\n    lastPos: incompleteExpression.length,\n  };\n}\n\n// No special handling for escaped versions of the characters\nfunction getUnbalancedChar(expression, leftChar, rightChar) {\n  let numOpen = 0;\n  for (const [m] of expression.matchAll(new RegExp(`[${escapeV(leftChar + rightChar, Context.CHAR_CLASS)}]`, 'g'))) {\n    numOpen += m === leftChar ? 1 : -1;\n    if (numOpen < 0) {\n      return rightChar;\n    }\n  }\n  if (numOpen > 0) {\n    return leftChar;\n  }\n  return '';\n}\n\n/**\n@typedef {import('./regex.js').InterpolatedValue} InterpolatedValue\n@typedef {import('./regex.js').RawTemplate} RawTemplate\n@typedef {import('./regex.js').RegexTagOptions} RegexTagOptions\n@typedef {(\n  value: InterpolatedValue,\n  runningContext: RunningContext,\n  options: Required<RegexTagOptions>\n) => {\n  transformed: string;\n  runningContext: RunningContext;\n}} Preprocessor\n*/\n/**\nReturns transformed versions of a template and substitutions, using the given preprocessor. Only\nprocesses substitutions that are instanceof `Pattern`.\n@param {RawTemplate} template\n@param {ReadonlyArray<InterpolatedValue>} substitutions\n@param {Preprocessor} preprocessor\n@param {Required<RegexTagOptions>} options\n@returns {{template: RawTemplate; substitutions: ReadonlyArray<InterpolatedValue>;}}\n*/\nexport function preprocess(template, substitutions, preprocessor, options) {\n  let /** @type {RawTemplate} */ newTemplate = {raw: []};\n  let newSubstitutions = [];\n  let runningContext;\n  template.raw.forEach((raw, i) => {\n    const result = preprocessor(raw, {...runningContext, lastPos: 0}, options);\n    newTemplate.raw.push(result.transformed);\n    runningContext = result.runningContext;\n    if (i < template.raw.length - 1) {\n      const substitution = substitutions[i];\n      if (substitution instanceof Pattern) {\n        const result = preprocessor(substitution, {...runningContext, lastPos: 0}, options);\n        newSubstitutions.push(pattern(result.transformed));\n        runningContext = result.runningContext;\n      } else {\n        newSubstitutions.push(substitution);\n      }\n    }\n  });\n  return {\n    template: newTemplate,\n    substitutions: newSubstitutions,\n  };\n}\n\n// Sandbox `^` if relevant, done so it can't change the meaning of the surrounding character class\n// if we happen to be at the first position. See `sandboxLoneDoublePunctuatorChar` for more details\nexport function sandboxLoneCharClassCaret(str) {\n  return str.replace(/^\\^/, '\\\\^^');\n}\n\n// Sandbox without escaping by repeating the character and escaping only the first one. The second\n// one is so that, if followed by the same symbol, the resulting double punctuator will still throw\n// as expected. Details:\n// - Only need to check the first position because, if it's part of an implicit union,\n//   interpolation handling will wrap it in nested `[\u2026]`.\n// - Can't just wrap in nested `[\u2026]` here, since the value might be used in a range.\n// - Can't add a second unescaped symbol if a lone symbol is the entire string because it might be\n//   followed by the same unescaped symbol outside an interpolation, and since it won't be wrapped,\n//   the second symbol wouldn't be sandboxed from the one following it.\nexport function sandboxLoneDoublePunctuatorChar(str) {\n  return str.replace(new RegExp(`^([${doublePunctuatorChars}])(?!\\\\1)`), (m, _, pos) => {\n    return `\\\\${m}${pos + 1 === str.length ? '' : m}`;\n  });\n}\n\n/**\nConverts `\\0` tokens to `\\x00` in the given context.\n@param {string} str\n@param {'DEFAULT' | 'CHAR_CLASS'} [context] `Context` option from lib `regex-utilities`\n@returns {string}\n*/\nexport function sandboxUnsafeNulls(str, context) {\n  // regex`[\\0${0}]` and regex`[${pattern`\\0`}0]` can't be guarded against via nested `[\u2026]`\n  // sandboxing in character classes if the interpolated value doesn't contain union (since it\n  // might be placed on a range boundary). So escape `\\0` in character classes as `\\x00`\n  return replaceUnescaped(str, String.raw`\\\\0(?!\\d)`, '\\\\x00', context);\n}\n\n/**\n@param {string} str\n@param {number} pos\n@param {string} oldValue\n@param {string} newValue\n@returns {string}\n*/\nexport function spliceStr(str, pos, oldValue, newValue) {\n  return str.slice(0, pos) + newValue + str.slice(pos + oldValue.length);\n}\n", "import {emulationGroupMarker} from './subclass.js';\nimport {noncapturingDelim, spliceStr} from './utils.js';\nimport {Context, replaceUnescaped} from 'regex-utilities';\n\nconst atomicPluginToken = new RegExp(String.raw`(?<noncapturingStart>${noncapturingDelim})|(?<capturingStart>\\((?:\\?<[^>]+>)?)|\\\\?.`, 'gsu');\n\n/**\nApply transformations for atomic groups: `(?>\u2026)`.\n@param {string} expression\n@param {import('./regex.js').PluginData} [data]\n@returns {string}\n*/\nexport function atomic(expression, data) {\n  if (!/\\(\\?>/.test(expression)) {\n    return expression;\n  }\n  const aGDelim = '(?>';\n  const emulatedAGDelim = `(?:(?=(${data?.useEmulationGroups ? emulationGroupMarker : ''}`;\n  const captureNumMap = [0];\n  let numCapturesBeforeAG = 0;\n  let numAGs = 0;\n  let aGPos = NaN;\n  let hasProcessedAG;\n  do {\n    hasProcessedAG = false;\n    let numCharClassesOpen = 0;\n    let numGroupsOpenInAG = 0;\n    let inAG = false;\n    let match;\n    atomicPluginToken.lastIndex = Number.isNaN(aGPos) ? 0 : aGPos + emulatedAGDelim.length;\n    while (match = atomicPluginToken.exec(expression)) {\n      const {0: m, index, groups: {capturingStart, noncapturingStart}} = match;\n      if (m === '[') {\n        numCharClassesOpen++;\n      } else if (!numCharClassesOpen) {\n\n        if (m === aGDelim && !inAG) {\n          aGPos = index;\n          inAG = true;\n        } else if (inAG && noncapturingStart) {\n          numGroupsOpenInAG++;\n        } else if (capturingStart) {\n          if (inAG) {\n            numGroupsOpenInAG++;\n          } else {\n            numCapturesBeforeAG++;\n            captureNumMap.push(numCapturesBeforeAG + numAGs);\n          }\n        } else if (m === ')' && inAG) {\n          if (!numGroupsOpenInAG) {\n            numAGs++;\n            // Replace `expression` and use `<$$N>` as a temporary wrapper for the backref so it\n            // can avoid backref renumbering afterward. Need to wrap the whole substitution\n            // (including the lookahead and following backref) in a noncapturing group to handle\n            // following quantifiers and literal digits\n            expression = `${expression.slice(0, aGPos)}${emulatedAGDelim}${\n                expression.slice(aGPos + aGDelim.length, index)\n              }))<$$${numAGs + numCapturesBeforeAG}>)${expression.slice(index + 1)}`;\n            hasProcessedAG = true;\n            break;\n          }\n          numGroupsOpenInAG--;\n        }\n\n      } else if (m === ']') {\n        numCharClassesOpen--;\n      }\n    }\n  // Start over from the beginning of the last atomic group's contents, in case the processed group\n  // contains additional atomic groups\n  } while (hasProcessedAG);\n\n  // Second pass to adjust numbered backrefs\n  expression = replaceUnescaped(\n    expression,\n    String.raw`\\\\(?<backrefNum>[1-9]\\d*)|<\\$\\$(?<wrappedBackrefNum>\\d+)>`,\n    ({0: m, groups: {backrefNum, wrappedBackrefNum}}) => {\n      if (backrefNum) {\n        const bNum = +backrefNum;\n        if (bNum > captureNumMap.length - 1) {\n          throw new Error(`Backref \"${m}\" greater than number of captures`);\n        }\n        return `\\\\${captureNumMap[bNum]}`;\n      }\n      return `\\\\${wrappedBackrefNum}`;\n    },\n    Context.DEFAULT\n  );\n  return expression;\n}\n\nconst baseQuantifier = String.raw`(?:[?*+]|\\{\\d+(?:,\\d*)?\\})`;\n// Complete tokenizer for base syntax; doesn't (need to) know about character-class-only syntax\nconst possessivePluginToken = new RegExp(String.raw`\n\\\\(?: \\d+\n  | c[A-Za-z]\n  | [gk]<[^>]+>\n  | [pPu]\\{[^\\}]+\\}\n  | u[A-Fa-f\\d]{4}\n  | x[A-Fa-f\\d]{2}\n  )\n| \\((?: \\? (?: [:=!>]\n  | <(?:[=!]|[^>]+>)\n  | [A-Za-z\\-]+:\n  | \\(DEFINE\\)\n  ))?\n| (?<qBase>${baseQuantifier})(?<qMod>[?+]?)(?<invalidQ>[?*+\\{]?)\n| \\\\?.\n`.replace(/\\s+/g, ''), 'gsu');\n\n/**\nTransform posessive quantifiers into atomic groups. The posessessive quantifiers are:\n`?+`, `*+`, `++`, `{N}+`, `{N,}+`, `{N,N}+`.\nThis follows Java, PCRE, Perl, and Python.\nPossessive quantifiers in Oniguruma and Onigmo are only: `?+`, `*+`, `++`.\n@param {string} expression\n@returns {string}\n*/\nexport function possessive(expression) {\n  if (!(new RegExp(`${baseQuantifier}\\\\+`).test(expression))) {\n    return expression;\n  }\n  const openGroupIndices = [];\n  let lastGroupIndex = null;\n  let lastCharClassIndex = null;\n  let lastToken = '';\n  let numCharClassesOpen = 0;\n  let match;\n  possessivePluginToken.lastIndex = 0;\n  while (match = possessivePluginToken.exec(expression)) {\n    const {0: m, index, groups: {qBase, qMod, invalidQ}} = match;\n    if (m === '[') {\n      if (!numCharClassesOpen) {\n        lastCharClassIndex = index;\n      }\n      numCharClassesOpen++;\n    } else if (m === ']') {\n      if (numCharClassesOpen) {\n        numCharClassesOpen--;\n      // Unmatched `]`\n      } else {\n        lastCharClassIndex = null;\n      }\n    } else if (!numCharClassesOpen) {\n\n      if (qMod === '+' && lastToken && !lastToken.startsWith('(')) {\n        // Invalid following quantifier would become valid via the wrapping group\n        if (invalidQ) {\n          throw new Error(`Invalid quantifier \"${m}\"`);\n        }\n        let charsAdded = -1; // -1 for removed trailing `+`\n        // Possessivizing fixed repetition quantifiers like `{2}` does't change their behavior, so\n        // avoid doing so (convert them to greedy)\n        if (/^\\{\\d+\\}$/.test(qBase)) {\n          expression = spliceStr(expression, index + qBase.length, qMod, '');\n        } else {\n          if (lastToken === ')' || lastToken === ']') {\n            const nodeIndex = lastToken === ')' ? lastGroupIndex : lastCharClassIndex;\n            // Unmatched `)` would break out of the wrapping group and mess with handling.\n            // Unmatched `]` wouldn't be a problem, but it's unnecessary to have dedicated support\n            // for unescaped `]++` since this won't work with flag u or v anyway\n            if (nodeIndex === null) {\n              throw new Error(`Invalid unmatched \"${lastToken}\"`);\n            }\n            expression = `${expression.slice(0, nodeIndex)}(?>${expression.slice(nodeIndex, index)}${qBase})${expression.slice(index + m.length)}`;\n          } else {\n            expression = `${expression.slice(0, index - lastToken.length)}(?>${lastToken}${qBase})${expression.slice(index + m.length)}`;\n          }\n          charsAdded += 4; // `(?>)`\n        }\n        possessivePluginToken.lastIndex += charsAdded;\n      } else if (m[0] === '(') {\n        openGroupIndices.push(index);\n      } else if (m === ')') {\n        lastGroupIndex = openGroupIndices.length ? openGroupIndices.pop() : null;\n      }\n\n    }\n    lastToken = m;\n  }\n  return expression;\n}\n", "import {Context, forEachUnescaped, getGroupContents, hasUnescaped, replaceUnescaped} from 'regex-utilities';\n\nconst gRToken = String.raw`\\\\g<(?<gRNameOrNum>[^>&]+)&R=(?<gRDepth>[^>]+)>`;\nconst recursiveToken = String.raw`\\(\\?R=(?<rDepth>[^\\)]+)\\)|${gRToken}`;\nconst namedCapturingDelim = String.raw`\\(\\?<(?![=!])(?<captureName>[^>]+)>`;\nconst token = new RegExp(String.raw`${namedCapturingDelim}|${recursiveToken}|\\(\\?|\\\\?.`, 'gsu');\nconst overlappingRecursionMsg = 'Cannot use multiple overlapping recursions';\n\n/**\n@param {string} expression\n@returns {string}\n*/\nexport function recursion(expression) {\n  // Keep the initial fail-check (which avoids unneeded processing) as fast as possible by testing\n  // without the accuracy improvement of using `hasUnescaped` with default `Context`\n  if (!(new RegExp(recursiveToken, 'su').test(expression))) {\n    return expression;\n  }\n  if (hasUnescaped(expression, String.raw`\\\\[1-9]`, Context.DEFAULT)) {\n    // Could add support for numbered backrefs with extra effort, but it's probably not worth it.\n    // To trigger this error, the regex must include recursion and one of the following:\n    // - An interpolated regex that contains a numbered backref (since other numbered backrefs are\n    //   prevented by implicit flag n).\n    // - A numbered backref, when flag n is explicitly disabled.\n    // Note that `regex`'s extended syntax (atomic groups and sometimes subroutines) can also add\n    // numbered backrefs, but those work fine because external plugins like this one run *before*\n    // the transpilation of built-in syntax extensions.\n    // To support numbered backrefs, they would need to be automatically adjusted when they're\n    // duplicated by recursion and refer to a group inside the expression being recursed.\n    // Additionally, numbered backrefs inside and outside of the recursed expression would need to\n    // be adjusted based on any capturing groups added by recursion.\n    throw new Error(`Numbered backrefs cannot be used with recursion`);\n  }\n  if (hasUnescaped(expression, String.raw`\\(\\?\\(DEFINE\\)`, Context.DEFAULT)) {\n    throw new Error(`DEFINE groups cannot be used with recursion`);\n  }\n  const groupContentsStartPos = new Map();\n  const openGroups = [];\n  let hasRecursed = false;\n  let numCharClassesOpen = 0;\n  let numCaptures = 0;\n  let match;\n  token.lastIndex = 0;\n  while ((match = token.exec(expression))) {\n    const {0: m, groups: {captureName, rDepth, gRNameOrNum, gRDepth}} = match;\n    if (m === '[') {\n      numCharClassesOpen++;\n    } else if (!numCharClassesOpen) {\n\n      // `(?R=N)`\n      if (rDepth) {\n        assertMaxInBounds(rDepth);\n        if (hasRecursed) {\n          throw new Error(overlappingRecursionMsg);\n        }\n        const pre = expression.slice(0, match.index);\n        const post = expression.slice(token.lastIndex);\n        if (hasUnescaped(post, recursiveToken, Context.DEFAULT)) {\n          throw new Error(overlappingRecursionMsg);\n        }\n        // No need to parse further\n        return makeRecursive(pre, post, +rDepth, false);\n      // `\\g<name&R=N>`, `\\g<number&R=N>`\n      } else if (gRNameOrNum) {\n        assertMaxInBounds(gRDepth);\n        let isWithinReffedGroup = false;\n        for (const g of openGroups) {\n          if (g.name === gRNameOrNum || g.num === +gRNameOrNum) {\n            isWithinReffedGroup = true;\n            if (g.hasRecursedWithin) {\n              throw new Error(overlappingRecursionMsg);\n            }\n            break;\n          }\n        }\n        if (!isWithinReffedGroup) {\n          throw new Error(`Recursive \\\\g cannot be used outside the referenced group \"\\\\g<${gRNameOrNum}&R=${gRDepth}>\"`);\n        }\n        const startPos = groupContentsStartPos.get(gRNameOrNum);\n        const groupContents = getGroupContents(expression, startPos);\n        const groupContentsPre = expression.slice(startPos, match.index);\n        const groupContentsPost = groupContents.slice(groupContentsPre.length + m.length);\n        const expansion = makeRecursive(groupContentsPre, groupContentsPost, +gRDepth, true);\n        const pre = expression.slice(0, startPos);\n        const post = expression.slice(startPos + groupContents.length);\n        // Modify the string we're looping over\n        expression = `${pre}${expansion}${post}`;\n        // Step forward for the next loop iteration\n        token.lastIndex += expansion.length - m.length - groupContentsPre.length - groupContentsPost.length;\n        openGroups.forEach(g => g.hasRecursedWithin = true);\n        hasRecursed = true;\n      } else if (captureName) {\n        numCaptures++;\n        groupContentsStartPos.set(String(numCaptures), token.lastIndex);\n        groupContentsStartPos.set(captureName, token.lastIndex);\n        openGroups.push({\n          num: numCaptures,\n          name: captureName,\n        });\n      } else if (m.startsWith('(')) {\n        const isUnnamedCapture = m === '(';\n        if (isUnnamedCapture) {\n          numCaptures++;\n          groupContentsStartPos.set(String(numCaptures), token.lastIndex);\n        }\n        openGroups.push(isUnnamedCapture ? {num: numCaptures} : {});\n      } else if (m === ')') {\n        openGroups.pop();\n      }\n\n    } else if (m === ']') {\n      numCharClassesOpen--;\n    }\n  }\n\n  return expression;\n}\n\n/**\n@param {string} max\n*/\nfunction assertMaxInBounds(max) {\n  const errMsg = `Max depth must be integer between 2 and 100; used ${max}`;\n  if (!/^[1-9]\\d*$/.test(max)) {\n    throw new Error(errMsg);\n  }\n  max = +max;\n  if (max < 2 || max > 100) {\n    throw new Error(errMsg);\n  }\n}\n\n/**\n@param {string} pre\n@param {string} post\n@param {number} maxDepth\n@param {boolean} isSubpattern\n@returns {string}\n*/\nfunction makeRecursive(pre, post, maxDepth, isSubpattern) {\n  const namesInRecursed = new Set();\n  // Avoid this work if not needed\n  if (isSubpattern) {\n    forEachUnescaped(pre + post, namedCapturingDelim, ({groups: {captureName}}) => {\n      namesInRecursed.add(captureName);\n    }, Context.DEFAULT);\n  }\n  const reps = maxDepth - 1;\n  // Depth 2: 'pre(?:pre(?:)post)post'\n  // Depth 3: 'pre(?:pre(?:pre(?:)post)post)post'\n  return `${pre}${\n    repeatWithDepth(`(?:${pre}`, reps, (isSubpattern ? namesInRecursed : null))\n  }(?:)${\n    repeatWithDepth(`${post})`, reps, (isSubpattern ? namesInRecursed : null), 'backward')\n  }${post}`;\n}\n\n/**\n@param {string} expression\n@param {number} reps\n@param {Set<string> | null} namesInRecursed\n@param {'forward' | 'backward'} [direction]\n@returns {string}\n*/\nfunction repeatWithDepth(expression, reps, namesInRecursed, direction = 'forward') {\n  const startNum = 2;\n  const depthNum = i => direction === 'backward' ? reps - i + startNum - 1 : i + startNum;\n  let result = '';\n  for (let i = 0; i < reps; i++) {\n    const captureNum = depthNum(i);\n    result += replaceUnescaped(\n      expression,\n      String.raw`${namedCapturingDelim}|\\\\k<(?<backref>[^>]+)>`,\n      ({0: m, groups: {captureName, backref}}) => {\n        if (backref && namesInRecursed && !namesInRecursed.has(backref)) {\n          // Don't alter backrefs to groups outside the recursed subpattern\n          return m;\n        }\n        const suffix = `_$${captureNum}`;\n        return captureName ? `(?<${captureName}${